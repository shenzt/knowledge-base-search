#!/usr/bin/env python3
"""Agentic RAG è‡ªåŠ¨åŒ–æµ‹è¯• - ä½¿ç”¨ Claude Agent SDK + Session å¤ç”¨

å…³é”®ä¼˜åŒ–ï¼šä½¿ç”¨ session resume ä¿æŒ MCP server æ´»è·ƒï¼Œé¿å…æ¯æ¬¡é‡æ–°åŠ è½½æ¨¡åž‹ã€‚
å®Œæ•´è®°å½•ä¸­é—´è¿‡ç¨‹åˆ°æ—¥å¿—æ–‡ä»¶ï¼Œæ–¹ä¾¿æŽ’æŸ¥å’Œè°ƒä¼˜ã€‚
"""

import asyncio
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from dotenv import load_dotenv
load_dotenv()

from claude_agent_sdk import query, ClaudeAgentOptions

PROJECT_ROOT = Path(__file__).parent.parent.parent

TEST_CASES = [
    # â”€â”€ åŸºç¡€å…³é”®è¯æŸ¥è¯¢ï¼ˆGrep æ“…é•¿ï¼‰â”€â”€ type: keyword
    {"id": "basic-001", "query": "What is a Pod in Kubernetes?", "category": "k8s-basic", "type": "keyword"},
    {"id": "basic-002", "query": "Kubernetes Service æ˜¯ä»€ä¹ˆï¼Ÿ", "category": "k8s-service", "type": "keyword"},
    {"id": "basic-003", "query": "What are Init Containers?", "category": "k8s-init", "type": "keyword"},

    # â”€â”€ ç²¾ç¡®å…³é”®è¯/é”™è¯¯ç ï¼ˆGrep æœ€å¼ºï¼‰â”€â”€ type: exact
    {"id": "grep-001", "query": "READONLY You can't write against a read only replica", "category": "redis-error",
     "type": "exact", "note": "ç²¾ç¡®é”™è¯¯ä¿¡æ¯ï¼ŒGrep ç›´æŽ¥å‘½ä¸­ redis-failover.md"},
    {"id": "grep-002", "query": "OOMKilled", "category": "k8s-oom",
     "type": "exact", "note": "ç²¾ç¡®é”™è¯¯ç ï¼ŒGrep ç›´æŽ¥å‘½ä¸­ k8s-crashloop.md"},
    {"id": "grep-003", "query": "TOKEN_EXPIRED é”™è¯¯ç æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ", "category": "api-errorcode",
     "type": "exact", "note": "ç²¾ç¡®é”™è¯¯ç ï¼ŒGrep å‘½ä¸­ authentication.md"},
    {"id": "grep-004", "query": "JWT token çš„ç»“æž„æ˜¯ä»€ä¹ˆï¼Ÿ", "category": "api-jwt",
     "type": "exact", "note": "ç²¾ç¡®å…³é”®è¯ JWTï¼ŒGrep å‘½ä¸­ authentication.md"},
    {"id": "grep-005", "query": "SENTINEL failover å‘½ä»¤æ€Žä¹ˆç”¨ï¼Ÿ", "category": "redis-sentinel",
     "type": "exact", "note": "ç²¾ç¡®å‘½ä»¤åï¼ŒGrep å‘½ä¸­ redis-failover.md"},

    # â”€â”€ ç—‡çŠ¶æè¿°åž‹ï¼ˆHybrid Search æ“…é•¿ï¼‰â”€â”€ type: semantic
    {"id": "semantic-001", "query": "åº”ç”¨çªç„¶æ— æ³•å†™å…¥ç¼“å­˜ï¼Œæ—¥å¿—æŠ¥åªè¯»é”™è¯¯", "category": "redis-symptom",
     "type": "semantic", "note": "ç—‡çŠ¶æè¿°â†’redis-failover.mdï¼Œæ— ç›´æŽ¥å…³é”®è¯åŒ¹é…"},
    {"id": "semantic-002", "query": "å®¹å™¨ä¸€ç›´é‡å¯ï¼Œæ— æ³•æ­£å¸¸è¿è¡Œ", "category": "k8s-symptom",
     "type": "semantic", "note": "ç—‡çŠ¶æè¿°â†’k8s-crashloop.mdï¼Œä¸å« CrashLoopBackOff å…³é”®è¯"},
    {"id": "semantic-003", "query": "å†…å­˜ä¸è¶³å¯¼è‡´è¿›ç¨‹è¢«æ€", "category": "k8s-oom-semantic",
     "type": "semantic", "note": "è¯­ä¹‰æè¿° OOMKilledï¼Œä¸å«è‹±æ–‡å…³é”®è¯"},
    {"id": "semantic-004", "query": "ç”¨æˆ·ç™»å½•åŽå¦‚ä½•ä¿æŒä¼šè¯çŠ¶æ€ï¼Ÿ", "category": "api-session",
     "type": "semantic", "note": "è¯­ä¹‰â†’authentication.md çš„ token æœºåˆ¶ï¼Œä¸å« JWT/OAuth å…³é”®è¯"},

    # â”€â”€ è·¨è¯­è¨€æŸ¥è¯¢ï¼ˆHybrid Search æ“…é•¿ï¼‰â”€â”€ type: cross-lang
    {"id": "cross-lang-001", "query": "Redis ç®¡é“æŠ€æœ¯å¦‚ä½•å·¥ä½œï¼Ÿ", "category": "redis-pipeline", "type": "cross-lang"},
    {"id": "cross-lang-002", "query": "How does Redis pipelining improve performance?", "category": "redis-pipeline", "type": "cross-lang"},
    {"id": "cross-lang-003", "query": "How to recover from Redis master-slave failover?", "category": "redis-cross",
     "type": "cross-lang", "note": "è‹±æ–‡æŸ¥è¯¢â†’ä¸­æ–‡æ–‡æ¡£ redis-failover.md"},
    {"id": "cross-lang-004", "query": "Kubernetes pod keeps crashing, how to debug?", "category": "k8s-cross",
     "type": "cross-lang", "note": "è‹±æ–‡å£è¯­åŒ–æŸ¥è¯¢â†’è‹±æ–‡æ–‡æ¡£ï¼Œä½†ä¸å«ç²¾ç¡®å…³é”®è¯ CrashLoopBackOff"},

    # â”€â”€ åŒä¹‰è¯æ”¹å†™åž‹ï¼ˆHybrid Search æ“…é•¿ï¼‰â”€â”€ type: paraphrase
    {"id": "paraphrase-001", "query": "å¦‚ä½•æ£€æŸ¥ Redis é«˜å¯ç”¨é›†ç¾¤çš„å¥åº·çŠ¶æ€ï¼Ÿ", "category": "redis-ha",
     "type": "paraphrase", "note": "é«˜å¯ç”¨â†’Sentinelï¼Œå¥åº·çŠ¶æ€â†’æŽ’æŸ¥æ­¥éª¤ï¼Œæ”¹å†™åŽæ— ç›´æŽ¥å…³é”®è¯"},
    {"id": "paraphrase-002", "query": "API æŽ¥å£çš„æƒé™æŽ§åˆ¶æ˜¯æ€Žä¹ˆè®¾è®¡çš„ï¼Ÿ", "category": "api-rbac",
     "type": "paraphrase", "note": "æƒé™æŽ§åˆ¶â†’RBACï¼Œæ”¹å†™åŽéœ€è¯­ä¹‰ç†è§£"},
    {"id": "paraphrase-003", "query": "åº”ç”¨è¿žæŽ¥æ•°æ®åº“ç¼“å­˜çš„æœ€ä½³å®žè·µ", "category": "redis-connpool",
     "type": "paraphrase", "note": "æ•°æ®åº“ç¼“å­˜â†’Redisï¼Œè¿žæŽ¥â†’è¿žæŽ¥æ± ï¼Œéœ€è¯­ä¹‰å…³è”"},

    # â”€â”€ å¤æ‚æŽ¨ç†/å¤šæ–‡æ¡£ï¼ˆSkills ç¬¬ä¸‰å±‚æ“…é•¿ï¼‰â”€â”€ type: complex
    {"id": "complex-001", "query": "What's the difference between Deployment and StatefulSet?", "category": "k8s-comparison", "type": "complex"},
    {"id": "complex-002", "query": "How to troubleshoot CrashLoopBackOff in Kubernetes?", "category": "k8s-troubleshooting", "type": "complex"},
    {"id": "complex-003", "query": "Kubernetes ä¸­å¦‚ä½•å®žçŽ°æœåŠ¡å‘çŽ°ï¼Ÿ", "category": "k8s-service-discovery", "type": "complex"},
    {"id": "complex-004", "query": "Pod å´©æºƒåŽ Redis è¿žæŽ¥ä¼šæ€Žæ ·ï¼Ÿéœ€è¦æ€Žä¹ˆå¤„ç†ï¼Ÿ", "category": "multi-doc",
     "type": "complex", "note": "éœ€è¦ç»¼åˆ k8s-crashloop + redis-failover ä¸¤ä¸ªæ–‡æ¡£"},
    {"id": "complex-005", "query": "ç³»ç»Ÿçš„å®‰å…¨æœºåˆ¶æœ‰å“ªäº›ï¼Ÿä»Žè®¤è¯åˆ°éƒ¨ç½²éƒ½è¯´è¯´", "category": "multi-doc-security",
     "type": "complex", "note": "éœ€è¦ç»¼åˆ authentication.md + configuration.md"},

    # â”€â”€ How-to å®žæ“åž‹ â”€â”€ type: howto
    {"id": "howto-001", "query": "How to create a Pod with multiple containers?", "category": "k8s-howto", "type": "howto"},
    {"id": "howto-002", "query": "å¦‚ä½•é…ç½® Kubernetes èµ„æºé™åˆ¶ï¼Ÿ", "category": "k8s-resources", "type": "howto"},
    {"id": "howto-003", "query": "refresh_token è¿‡æœŸäº†æ€Žä¹ˆåŠžï¼Ÿ", "category": "api-refresh",
     "type": "howto", "note": "å®žæ“é—®é¢˜â†’authentication.md çš„ token åˆ·æ–°æµç¨‹"},
    {"id": "howto-004", "query": "æ€Žä¹ˆé…ç½® Redis è¿žæŽ¥æ± çš„ç©ºé—²è¶…æ—¶ï¼Ÿ", "category": "redis-config",
     "type": "howto", "note": "å®žæ“â†’redis-failover.md çš„ minEvictableIdleTimeMillis"},

    # â”€â”€ æ¦‚å¿µåž‹ â”€â”€ type: concept
    {"id": "concept-001", "query": "What is the purpose of a ReplicaSet?", "category": "k8s-concept", "type": "concept"},
    {"id": "concept-002", "query": "Kubernetes å‘½åç©ºé—´çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ", "category": "k8s-namespace", "type": "concept"},

    # â”€â”€ è¾¹ç¼˜åž‹ â”€â”€ type: concept
    {"id": "edge-001", "query": "What is a sidecar container?", "category": "k8s-pattern", "type": "concept"},
    {"id": "edge-002", "query": "Kubernetes ä¸­çš„ DaemonSet æ˜¯ä»€ä¹ˆï¼Ÿ", "category": "k8s-daemonset", "type": "concept"},

    # â”€â”€ æœªæ”¶å½•ï¼ˆåº”è¿”å›ž"æœªæ‰¾åˆ°"ï¼‰â”€â”€ type: notfound
    {"id": "notfound-001", "query": "How to configure Kubernetes with blockchain?", "category": "not-in-kb", "type": "notfound", "expect_no_results": True},
    {"id": "notfound-002", "query": "MongoDB åˆ†ç‰‡é›†ç¾¤å¦‚ä½•é…ç½®ï¼Ÿ", "category": "not-in-kb", "type": "notfound", "expect_no_results": True},
]

KEYWORD_CHECKS = {
    "k8s-basic": ["pod", "container", "kubernetes"],
    "k8s-service": ["service", "ç½‘ç»œ", "network", "è´Ÿè½½", "load"],
    "k8s-init": ["init", "container", "åˆå§‹åŒ–"],
    "redis-pipeline": ["pipeline", "ç®¡é“", "æ‰¹é‡", "batch", "redis"],
    "k8s-comparison": ["deployment", "statefulset", "åŒºåˆ«", "difference"],
    "k8s-troubleshooting": ["crashloopbackoff", "debug", "æŽ’æŸ¥", "troubleshoot", "log"],
    "k8s-service-discovery": ["service", "discovery", "å‘çŽ°", "dns"],
    "k8s-howto": ["pod", "container", "multi", "å¤šå®¹å™¨", "sidecar"],
    "k8s-resources": ["resource", "limit", "request", "èµ„æº", "cpu", "memory"],
    "k8s-concept": ["replicaset", "replica", "å‰¯æœ¬"],
    "k8s-namespace": ["namespace", "å‘½åç©ºé—´", "éš”ç¦»"],
    "k8s-pattern": ["sidecar", "container", "pattern"],
    "k8s-daemonset": ["daemonset", "node", "èŠ‚ç‚¹"],
    # â”€â”€ æ–°å¢ž category çš„å…³é”®è¯æ£€æŸ¥ â”€â”€
    "redis-error": ["readonly", "read only", "replica", "å†™å…¥", "failover", "åˆ‡æ¢"],
    "k8s-oom": ["oomkilled", "oom", "memory", "å†…å­˜", "limit"],
    "api-errorcode": ["token_expired", "è¿‡æœŸ", "401", "é”™è¯¯ç ", "error"],
    "api-jwt": ["jwt", "token", "sub", "exp", "ç­¾å", "signature"],
    "redis-sentinel": ["sentinel", "failover", "ä¸»ä»Ž", "åˆ‡æ¢"],
    "redis-symptom": ["redis", "readonly", "å†™å…¥", "failover", "sentinel", "ä¸»ä»Ž", "åˆ‡æ¢", "åªè¯»"],
    "k8s-symptom": ["crash", "restart", "é‡å¯", "crashloop", "pod", "å®¹å™¨"],
    "k8s-oom-semantic": ["oom", "memory", "å†…å­˜", "killed", "limit", "èµ„æº"],
    "api-session": ["token", "jwt", "oauth", "è®¤è¯", "ç™»å½•", "session", "ä¼šè¯"],
    "redis-cross": ["failover", "sentinel", "master", "slave", "åˆ‡æ¢", "æ¢å¤", "redis"],
    "k8s-cross": ["crash", "debug", "log", "pod", "restart", "troubleshoot"],
    "redis-ha": ["sentinel", "redis", "é«˜å¯ç”¨", "health", "çŠ¶æ€", "master"],
    "api-rbac": ["rbac", "role", "æƒé™", "admin", "viewer", "editor", "æŽˆæƒ"],
    "redis-connpool": ["è¿žæŽ¥æ± ", "connection", "sentinel", "redis", "é…ç½®", "testOnBorrow"],
    "multi-doc": ["pod", "redis", "crash", "è¿žæŽ¥", "é‡å¯", "failover"],
    "multi-doc-security": ["è®¤è¯", "oauth", "jwt", "token", "å®‰å…¨", "https", "æƒé™"],
    "api-refresh": ["refresh", "token", "è¿‡æœŸ", "åˆ·æ–°", "access_token"],
    "redis-config": ["è¿žæŽ¥æ± ", "idle", "timeout", "minEvictable", "é…ç½®", "è¶…æ—¶"],
}

# æ˜¯å¦å¯ç”¨ MCPï¼ˆæ¨¡åž‹åŠ è½½éœ€è¦ 15-20 åˆ†é’Ÿï¼Œå¯é€‰å…³é—­ï¼‰
USE_MCP = os.environ.get("USE_MCP", "0") == "1"

if USE_MCP:
    BASE_OPTIONS = dict(
        allowed_tools=[
            "Read", "Grep", "Glob", "Bash",
            "mcp__knowledge-base__hybrid_search",
            "mcp__knowledge-base__keyword_search",
            "mcp__knowledge-base__index_status",
        ],
        mcp_servers={
            "knowledge-base": {
                "command": str(PROJECT_ROOT / ".venv" / "bin" / "python"),
                "args": [str(PROJECT_ROOT / "scripts" / "mcp_server.py")],
                "env": {
                    "QDRANT_URL": os.environ.get("QDRANT_URL", "http://localhost:6333"),
                    "COLLECTION_NAME": os.environ.get("COLLECTION_NAME", "knowledge-base"),
                },
            }
        },
        setting_sources=["project"],
        permission_mode="bypassPermissions",
        cwd=str(PROJECT_ROOT),
        max_turns=15,
    )
else:
    # æ—  MCP æ¨¡å¼ï¼šä»…ä½¿ç”¨ Grep/Glob/Readï¼ˆAgentic Layer 1ï¼‰
    # æ³¨æ„ï¼šä¸èƒ½ç”¨ setting_sources=["project"]ï¼Œå¦åˆ™ä¼šåŠ è½½ .mcp.json å¯åŠ¨ MCP server
    # æ”¹ç”¨ system_prompt æ³¨å…¥ CLAUDE.md å’Œ search skill çš„å…³é”®æŒ‡ä»¤
    BASE_OPTIONS = dict(
        allowed_tools=["Read", "Grep", "Glob", "Bash"],
        permission_mode="bypassPermissions",
        cwd=str(PROJECT_ROOT),
        max_turns=15,
        system_prompt="""ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†åº“æ£€ç´¢åŠ©æ‰‹ã€‚ç”¨æˆ·ä¼šç”¨ /search å‘½ä»¤æŸ¥è¯¢çŸ¥è¯†åº“ã€‚

çŸ¥è¯†åº“æ–‡æ¡£åœ¨ docs/ ç›®å½•ä¸‹ï¼Œæ ¼å¼ä¸º Markdownï¼ŒåŒ…å« Kubernetes å’Œ Redis ç›¸å…³æŠ€æœ¯æ–‡æ¡£ã€‚

æ£€ç´¢ç­–ç•¥ï¼š
1. ä½¿ç”¨ Grep æœç´¢å…³é”®è¯
2. ä½¿ç”¨ Glob æŸ¥æ‰¾ç›¸å…³æ–‡ä»¶ï¼ˆå¦‚ docs/**/*.mdï¼‰
3. ä½¿ç”¨ Read è¯»å–å‘½ä¸­æ–‡ä»¶çš„ç›¸å…³æ®µè½
4. ç»¼åˆåˆ†æžå¹¶å›žç­”ï¼Œå¿…é¡»å¸¦å¼•ç”¨ [æ¥æº: docs/xxx.md]

å›žç­”è¦æ±‚ï¼š
- åŸºäºŽæ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹å›žç­”
- å¦‚æžœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæ˜Žç¡®è¯´æ˜Ž"æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£"
- å›žç­”è¯­è¨€è·ŸéšæŸ¥è¯¢è¯­è¨€ï¼ˆä¸­æ–‡é—®ä¸­æ–‡ç­”ï¼Œè‹±æ–‡é—®è‹±æ–‡ç­”ï¼‰
- å¼•ç”¨å…·ä½“æ–‡æ¡£è·¯å¾„
""",
    )


def log(msg: str, log_file=None):
    """åŒæ—¶è¾“å‡ºåˆ° stdout å’Œæ—¥å¿—æ–‡ä»¶"""
    print(msg, flush=True)
    if log_file:
        log_file.write(msg + "\n")
        log_file.flush()


async def run_query(prompt: str, session_id: Optional[str], log_file) -> Dict[str, Any]:
    """æ‰§è¡Œå•ä¸ªæŸ¥è¯¢ï¼Œå®Œæ•´è®°å½•ä¸­é—´è¿‡ç¨‹"""
    start = time.time()
    answer = ""
    new_session_id = session_id
    cost = 0.0
    num_turns = 0
    tools_used = []
    messages_log = []  # å®Œæ•´æ¶ˆæ¯æ—¥å¿—

    try:
        if session_id:
            opts = ClaudeAgentOptions(
                resume=session_id,
                permission_mode="bypassPermissions",
                max_turns=15,
            )
        else:
            opts = ClaudeAgentOptions(**BASE_OPTIONS)

        async for msg in query(prompt=prompt, options=opts):
            # è®°å½•æ¯æ¡æ¶ˆæ¯çš„å®Œæ•´ä¿¡æ¯
            msg_dict = {}
            for attr in ["type", "subtype", "role", "result", "session_id",
                         "cost_usd", "num_turns", "tool_name", "tool_input",
                         "tool_result", "content", "text", "data",
                         "stop_reason", "duration_ms", "total_cost_usd",
                         "usage", "modelUsage", "permission_denials"]:
                val = getattr(msg, attr, None)
                if val is not None:
                    try:
                        json.dumps(val)  # ç¡®ä¿å¯åºåˆ—åŒ–
                        msg_dict[attr] = val
                    except (TypeError, ValueError):
                        msg_dict[attr] = str(val)

            messages_log.append(msg_dict)

            # è¯¦ç»†æ—¥å¿—è¾“å‡º - è§£æž SDK æ¶ˆæ¯ç»“æž„
            subtype = getattr(msg, "subtype", None)
            content = getattr(msg, "content", None)

            if subtype == "init":
                data = getattr(msg, "data", {}) or {}
                if isinstance(data, dict):
                    new_session_id = data.get("session_id", new_session_id)
                    model = data.get("model", "unknown")
                    log(f"    [INIT] session={new_session_id} model={model}", log_file)
                if hasattr(msg, "session_id"):
                    new_session_id = msg.session_id

            elif subtype == "success":
                # æœ€ç»ˆç»“æžœ
                if hasattr(msg, "result"):
                    answer = msg.result if isinstance(msg.result, str) else str(msg.result)
                num_turns = getattr(msg, "num_turns", num_turns)
                cost = getattr(msg, "total_cost_usd", cost) or cost
                duration = getattr(msg, "duration_ms", 0)
                log(f"    [RESULT] {len(answer)} chars | {num_turns} turns | {duration}ms", log_file)

            elif content:
                # è§£æž content blocksï¼ˆTextBlock, ToolUseBlock, ToolResultBlockï¼‰
                if isinstance(content, list):
                    for block in content:
                        block_type = getattr(block, "type", None)
                        if block_type is None and isinstance(block, dict):
                            block_type = block.get("type", "")

                        if block_type == "text" or (hasattr(block, "text") and not hasattr(block, "name") and not hasattr(block, "tool_use_id")):
                            # TextBlock - Claude çš„æŽ¨ç†/å›žå¤
                            text = getattr(block, "text", "") if hasattr(block, "text") else block.get("text", "")
                            if text:
                                # å¤šè¡Œæ–‡æœ¬æˆªæ–­æ˜¾ç¤º
                                lines = text.strip().split("\n")
                                preview = lines[0][:200]
                                if len(lines) > 1:
                                    preview += f" (+{len(lines)-1} lines)"
                                log(f"    [THINK] {preview}", log_file)

                        elif block_type == "tool_use" or hasattr(block, "name"):
                            # ToolUseBlock - å·¥å…·è°ƒç”¨
                            tool_name = getattr(block, "name", "unknown")
                            tool_input = getattr(block, "input", {})
                            if isinstance(tool_input, dict):
                                input_str = json.dumps(tool_input, ensure_ascii=False)
                            else:
                                input_str = str(tool_input)
                            if len(input_str) > 300:
                                input_str = input_str[:300] + "..."
                            log(f"    [TOOL] {tool_name}({input_str})", log_file)
                            tools_used.append(tool_name)

                        elif block_type == "tool_result" or hasattr(block, "tool_use_id"):
                            # ToolResultBlock - å·¥å…·è¿”å›ž
                            result_content = getattr(block, "content", "")
                            if isinstance(result_content, str):
                                # æˆªæ–­é•¿ç»“æžœï¼Œä¿ç•™å…³é”®ä¿¡æ¯
                                lines = result_content.strip().split("\n")
                                if len(lines) > 5:
                                    preview = "\n".join(lines[:3]) + f"\n    ... ({len(lines)} lines total)"
                                else:
                                    preview = result_content[:400]
                                log(f"    [TOOL_OUT] {preview}", log_file)
                            elif isinstance(result_content, list):
                                for rc in result_content:
                                    rc_text = getattr(rc, "text", str(rc)) if hasattr(rc, "text") else str(rc)
                                    log(f"    [TOOL_OUT] {rc_text[:300]}", log_file)

            # æå–å…ƒæ•°æ®
            if hasattr(msg, "cost_usd") and msg.cost_usd:
                cost = msg.cost_usd
            if hasattr(msg, "total_cost_usd") and msg.total_cost_usd:
                cost = msg.total_cost_usd
            if hasattr(msg, "num_turns") and msg.num_turns:
                num_turns = msg.num_turns

            # æ£€æŸ¥ permission denials
            denials = getattr(msg, "permission_denials", None)
            if denials:
                for d in denials:
                    tool = d.get("tool_name", "unknown") if isinstance(d, dict) else str(d)
                    log(f"    [DENIED] {tool}", log_file)

        elapsed = time.time() - start
        return {
            "status": "success",
            "answer": answer,
            "session_id": new_session_id,
            "elapsed": elapsed,
            "cost_usd": cost,
            "num_turns": num_turns,
            "tools_used": tools_used,
            "messages_log": messages_log,
        }
    except Exception as e:
        elapsed = time.time() - start
        log(f"    [ERROR] {e}", log_file)
        return {
            "status": "error",
            "error": str(e),
            "session_id": new_session_id,
            "elapsed": elapsed,
            "messages_log": messages_log,
        }


def evaluate(tc: Dict, result: Dict) -> Dict:
    """è¯„ä¼°ç­”æ¡ˆ"""
    ev = {"passed": False, "reasons": [], "quality": {}}
    if result["status"] != "success":
        ev["reasons"].append(f"æ‰§è¡Œå¤±è´¥: {result.get('error', '')[:80]}")
        return ev

    answer = result.get("answer", "")

    if tc.get("expect_no_results"):
        nf = ["æœªæ‰¾åˆ°", "æ²¡æœ‰æ‰¾åˆ°", "not found", "no relevant", "æ— æ³•æ‰¾åˆ°", "no results", "æ²¡æœ‰ç›¸å…³", "don't have"]
        if any(w.lower() in answer.lower() for w in nf) or len(answer) < 500:
            ev["passed"] = True
            ev["quality"]["no_results_ok"] = True
        else:
            ev["reasons"].append("åº”è¯†åˆ«ä¸ºæ— ç»“æžœ")
        return ev

    if len(answer) < 50:
        ev["reasons"].append(f"ç­”æ¡ˆè¿‡çŸ­ ({len(answer)})")
        return ev

    ev["quality"]["has_citation"] = any(m in answer for m in ["æ¥æº:", "docs/", "[æ¥æº", ".md"])
    expected = KEYWORD_CHECKS.get(tc["category"], [])
    matched = [k for k in expected if k.lower() in answer.lower()]
    ev["quality"]["keywords"] = matched

    if len(answer) >= 100 and len(matched) >= 1:
        ev["passed"] = True
    else:
        if len(answer) < 100:
            ev["reasons"].append(f"å†…å®¹ä¸è¶³ ({len(answer)})")
        if not matched:
            ev["reasons"].append(f"ç¼ºå…³é”®è¯ ({expected})")
    return ev


async def main():
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_dir = PROJECT_ROOT / "eval" / "logs"
    log_dir.mkdir(parents=True, exist_ok=True)
    log_path = log_dir / f"agentic_rag_{timestamp}.log"
    detail_path = log_dir / f"agentic_rag_{timestamp}_detail.jsonl"

    with open(log_path, "w", encoding="utf-8") as lf, \
         open(detail_path, "w", encoding="utf-8") as df:

        mode = "MCP + Grep/Glob/Read" if USE_MCP else "Grep/Glob/Read (æ—  MCP)"
        log("=" * 80, lf)
        log(f"ðŸ¤– Agentic RAG æµ‹è¯• (Agent SDK)", lf)
        log("=" * 80, lf)
        log(f"ç”¨ä¾‹: {len(TEST_CASES)} | æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", lf)
        log(f"æ¨¡å¼: {mode}", lf)
        log(f"ç­–ç•¥: Claude è‡ªä¸»é€‰æ‹©æ£€ç´¢ç­–ç•¥ (Grep/Glob/Read{' + MCP hybrid_search' if USE_MCP else ''})", lf)
        log(f"æ—¥å¿—: {log_path}", lf)
        log(f"è¯¦ç»†: {detail_path}", lf)
        log("", lf)

        results = []
        passed = failed = errors = 0
        total_time = total_cost = 0.0
        session_id = None

        for i, tc in enumerate(TEST_CASES, 1):
            log(f"\n{'='*60}", lf)
            log(f"[{i}/{len(TEST_CASES)}] {tc['id']} ({tc['category']}) [{tc.get('type', '?')}]", lf)
            log(f"  Q: {tc['query']}", lf)
            if tc.get("note"):
                log(f"  ðŸ’¡ {tc['note']}", lf)
            if i == 1:
                log(f"  â³ é¦–æ¬¡æŸ¥è¯¢ï¼ŒåŠ è½½ MCP server (BGE-M3)...", lf)
            log(f"  å¼€å§‹: {datetime.now().strftime('%H:%M:%S')}", lf)

            # å¦‚æžœæœ‰ MCP + skillsï¼Œç”¨ /searchï¼›å¦åˆ™ç›´æŽ¥æé—®
            prompt = f"/search {tc['query']}" if USE_MCP else f"è¯·åœ¨ docs/ ç›®å½•ä¸­æ£€ç´¢å¹¶å›žç­”: {tc['query']}"
            result = await run_query(prompt, session_id, lf)

            if result.get("session_id"):
                session_id = result["session_id"]
                if i == 1:
                    log(f"  ðŸ“Œ Session: {session_id}", lf)

            elapsed = result.get("elapsed", 0)
            total_time += elapsed
            total_cost += result.get("cost_usd", 0)

            ev = evaluate(tc, result)

            if result["status"] == "error":
                log(f"  âŒ é”™è¯¯: {result.get('error', '')[:80]}", lf)
                errors += 1
                status = "error"
            elif ev["passed"]:
                ans_len = len(result.get("answer", ""))
                tools = set(result.get("tools_used", []))
                cite = "å¼•ç”¨âœ…" if ev["quality"].get("has_citation") else "å¼•ç”¨âŒ"
                kw = ev.get("quality", {}).get("keywords", [])
                log(f"  âœ… é€šè¿‡ | {ans_len}å­—ç¬¦ | {elapsed:.1f}s | ${result.get('cost_usd', 0):.4f} | {cite}", lf)
                if tools:
                    log(f"  ðŸ”§ å·¥å…·: {', '.join(tools)}", lf)
                if kw:
                    log(f"  ðŸ”‘ å…³é”®è¯: {', '.join(kw)}", lf)
                passed += 1
                status = "passed"
            else:
                log(f"  âŒ å¤±è´¥: {'; '.join(ev['reasons'])}", lf)
                failed += 1
                status = "failed"

            log(f"  ç»“æŸ: {datetime.now().strftime('%H:%M:%S')} | è€—æ—¶: {elapsed:.1f}s", lf)

            # å†™å…¥è¯¦ç»† JSONLï¼ˆæ¯ä¸ª query ä¸€è¡Œï¼ŒåŒ…å«å®Œæ•´æ¶ˆæ¯æ—¥å¿—ï¼‰
            detail_record = {
                "test_id": tc["id"],
                "category": tc["category"],
                "type": tc.get("type", "unknown"),
                "query": tc["query"],
                "status": status,
                "elapsed_seconds": elapsed,
                "cost_usd": result.get("cost_usd", 0),
                "num_turns": result.get("num_turns", 0),
                "answer_length": len(result.get("answer", "")),
                "answer": result.get("answer", ""),
                "tools_used": list(set(result.get("tools_used", []))),
                "has_citation": ev.get("quality", {}).get("has_citation", False),
                "matched_keywords": ev.get("quality", {}).get("keywords", []),
                "failure_reasons": ev.get("reasons", []),
                "messages": result.get("messages_log", []),
            }
            df.write(json.dumps(detail_record, ensure_ascii=False) + "\n")
            df.flush()

            results.append({
                "test_id": tc["id"], "category": tc["category"],
                "type": tc.get("type", "unknown"), "query": tc["query"],
                "status": status, "elapsed_seconds": elapsed,
                "cost_usd": result.get("cost_usd", 0),
                "num_turns": result.get("num_turns", 0),
                "answer_length": len(result.get("answer", "")),
                "tools_used": list(set(result.get("tools_used", []))),
                "has_citation": ev.get("quality", {}).get("has_citation", False),
                "matched_keywords": ev.get("quality", {}).get("keywords", []),
                "failure_reasons": ev.get("reasons", []),
                "answer_preview": result.get("answer", "")[:300],
            })
            log("-" * 80, lf)

        # æ€»ç»“
        total = len(TEST_CASES)
        log(f"\n{'=' * 80}", lf)
        log(f"ðŸ“Š æ€»ç»“: âœ…{passed} âŒ{failed} âš ï¸{errors} / {total} ({passed/total*100:.1f}%)", lf)
        log(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f}s | å¹³å‡: {total_time/max(passed+failed,1):.1f}s", lf)
        log(f"ðŸ’° æ€»è´¹ç”¨: ${total_cost:.4f}", lf)

        # æŒ‰æŸ¥è¯¢ç±»åž‹ç»Ÿè®¡
        type_stats = {}
        for i2, r in enumerate(results):
            qtype = TEST_CASES[i2].get("type", "unknown")
            type_stats.setdefault(qtype, {"t": 0, "p": 0})
            type_stats[qtype]["t"] += 1
            if r["status"] == "passed": type_stats[qtype]["p"] += 1

        log("", lf)
        log("ðŸ“ˆ æŒ‰æŸ¥è¯¢ç±»åž‹:", lf)
        type_labels = {
            "keyword": "å…³é”®è¯åŸºç¡€", "exact": "ç²¾ç¡®åŒ¹é…(Grepæ“…é•¿)",
            "semantic": "è¯­ä¹‰/ç—‡çŠ¶(Hybridæ“…é•¿)", "cross-lang": "è·¨è¯­è¨€",
            "paraphrase": "åŒä¹‰æ”¹å†™(Hybridæ“…é•¿)", "complex": "å¤æ‚æŽ¨ç†/å¤šæ–‡æ¡£",
            "howto": "å®žæ“é—®ç­”", "concept": "æ¦‚å¿µåž‹", "notfound": "æœªæ”¶å½•",
        }
        for t, s in sorted(type_stats.items()):
            r2 = s["p"]/s["t"]*100
            label = type_labels.get(t, t)
            log(f"  {'âœ…' if r2==100 else 'âš ï¸' if r2>0 else 'âŒ'} {label}: {s['p']}/{s['t']} ({r2:.0f}%)", lf)

        log("", lf)
        log("ðŸ“‹ æŒ‰ category:", lf)
        cats = {}
        for r in results:
            c = r["category"]
            cats.setdefault(c, {"t": 0, "p": 0})
            cats[c]["t"] += 1
            if r["status"] == "passed": cats[c]["p"] += 1
        for c, s in sorted(cats.items()):
            r2 = s["p"]/s["t"]*100
            log(f"  {'âœ…' if r2==100 else 'âš ï¸' if r2>0 else 'âŒ'} {c}: {s['p']}/{s['t']} ({r2:.0f}%)", lf)

        # ä¿å­˜æ±‡æ€» JSON
        out_dir = PROJECT_ROOT / "eval"
        out_file = out_dir / f"agentic_rag_test_{timestamp}.json"
        with open(out_file, "w", encoding="utf-8") as f:
            json.dump({
                "timestamp": datetime.now().isoformat(), "test_type": "agentic_rag",
                "method": "claude_agent_sdk_session_reuse", "total": total,
                "passed": passed, "failed": failed, "errors": errors,
                "total_time": total_time, "total_cost": total_cost,
                "type_stats": {t: {"total": s["t"], "passed": s["p"]} for t, s in type_stats.items()},
                "results": results,
            }, f, indent=2, ensure_ascii=False)

        log(f"\nðŸ“ æ±‡æ€»: {out_file}", lf)
        log(f"ðŸ“‹ æ—¥å¿—: {log_path}", lf)
        log(f"ðŸ“ è¯¦ç»†: {detail_path}", lf)

    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    generate_comparison(str(out_file))
    return results


def generate_comparison(agentic_file: str):
    """ç”Ÿæˆ Simple RAG vs Agentic RAG å¯¹æ¯”"""
    baseline = PROJECT_ROOT / "eval" / "comprehensive_test_20260213_234320.json"
    if not baseline.exists():
        candidates = sorted((PROJECT_ROOT / "eval").glob("comprehensive_test_*.json"))
        if not candidates:
            print("âŒ æœªæ‰¾åˆ° Simple RAG baseline", flush=True)
            return
        baseline = candidates[-1]

    with open(baseline) as f: simple = json.load(f)
    with open(agentic_file) as f: agentic = json.load(f)

    s_map = {r["test_id"]: r for r in simple["results"]}
    a_map = {r["test_id"]: r for r in agentic["results"]}
    s_rate = simple["passed"]/simple["total"]*100
    a_rate = agentic["passed"]/agentic["total"]*100
    s_avg = simple.get("total_time",0)/simple["total"]
    a_avg = agentic.get("total_time",0)/agentic["total"]

    improved = [t for t in TEST_CASES if s_map.get(t["id"],{}).get("status")!="passed" and a_map.get(t["id"],{}).get("status")=="passed"]
    regressed = [t for t in TEST_CASES if s_map.get(t["id"],{}).get("status")=="passed" and a_map.get(t["id"],{}).get("status")!="passed"]

    report = f"""# Simple RAG vs Agentic RAG å¯¹æ¯”æŠ¥å‘Š

**æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | **æ–¹æ³•**: Claude Agent SDK + Session å¤ç”¨

## ðŸ“Š æ€»ä½“

| æŒ‡æ ‡ | Simple RAG | Agentic RAG | å˜åŒ– |
|------|-----------|-------------|------|
| é€šè¿‡çŽ‡ | {simple['passed']}/{simple['total']} ({s_rate:.1f}%) | {agentic['passed']}/{agentic['total']} ({a_rate:.1f}%) | **{a_rate-s_rate:+.1f}%** |
| å¤±è´¥ | {simple['failed']} | {agentic['failed']} | {agentic['failed']-simple['failed']:+d} |
| å¹³å‡è€—æ—¶ | {s_avg:.1f}s | {a_avg:.1f}s | {a_avg-s_avg:+.1f}s |
| è´¹ç”¨ | ~${simple.get('total_tokens',0)*0.000003:.4f} | ${agentic.get('total_cost',0):.4f} | - |

## é€ç”¨ä¾‹

| ID | æŸ¥è¯¢ | Simple | Agentic | |
|----|------|--------|---------|--|
"""
    for tc in TEST_CASES:
        s = "âœ…" if s_map.get(tc["id"],{}).get("status")=="passed" else "âŒ"
        a = "âœ…" if a_map.get(tc["id"],{}).get("status")=="passed" else "âŒ"
        ch = "ðŸŸ¢" if s=="âŒ" and a=="âœ…" else "ðŸ”´" if s=="âœ…" and a=="âŒ" else ""
        q = tc["query"][:35]+"..." if len(tc["query"])>35 else tc["query"]
        report += f"| {tc['id']} | {q} | {s} | {a} | {ch} |\n"

    if improved:
        report += f"\n## ðŸŸ¢ æ”¹å–„ ({len(improved)})\n\n"
        for tc in improved:
            a = a_map.get(tc["id"],{})
            report += f"- **{tc['id']}**: {tc['query']} â†’ {a.get('answer_length',0)}å­—ç¬¦, å·¥å…·: {', '.join(a.get('tools_used',[]))}\n"

    if regressed:
        report += f"\n## ðŸ”´ é€€æ­¥ ({len(regressed)})\n\n"
        for tc in regressed:
            a = a_map.get(tc["id"],{})
            report += f"- **{tc['id']}**: {tc['query']} â†’ {'; '.join(a.get('failure_reasons',[]))}\n"

    report += f"\n## ç»“è®º\n\né€šè¿‡çŽ‡ {s_rate:.1f}% â†’ {a_rate:.1f}% ({a_rate-s_rate:+.1f}%), æ”¹å–„ {len(improved)} ä¸ª, é€€æ­¥ {len(regressed)} ä¸ªã€‚\n"

    rf = PROJECT_ROOT / "eval" / f"AGENTIC_VS_SIMPLE_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    with open(rf, "w", encoding="utf-8") as f: f.write(report)
    print(f"ðŸ“Š æŠ¥å‘Š: {rf}", flush=True)


if __name__ == "__main__":
    asyncio.run(main())
