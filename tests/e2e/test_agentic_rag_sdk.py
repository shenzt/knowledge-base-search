#!/usr/bin/env python3
"""Agentic RAG è‡ªåŠ¨åŒ–æµ‹è¯• - ä½¿ç”¨ Claude Agent SDK + Session å¤ç”¨

å…³é”®ä¼˜åŒ–ï¼šä½¿ç”¨ session resume ä¿æŒ MCP server æ´»è·ƒï¼Œé¿å…æ¯æ¬¡é‡æ–°åŠ è½½æ¨¡å‹ã€‚
å®Œæ•´è®°å½•ä¸­é—´è¿‡ç¨‹åˆ°æ—¥å¿—æ–‡ä»¶ï¼Œæ–¹ä¾¿æ’æŸ¥å’Œè°ƒä¼˜ã€‚
"""

import asyncio
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from dotenv import load_dotenv
load_dotenv()

from claude_agent_sdk import query, ClaudeAgentOptions

PROJECT_ROOT = Path(__file__).parent.parent.parent

# å¯¼å…¥è¯„æµ‹æ¨¡å—
sys.path.insert(0, str(PROJECT_ROOT / "scripts"))
from eval_module import extract_contexts, gate_check, get_tools_used, get_retrieved_doc_paths, get_kb_commit

TEST_CASES = [
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # v3: åŸºäºå…¨é‡ K8s + Redis å®˜æ–¹æ–‡æ¡£çš„æµ‹è¯•ç”¨ä¾‹
    #
    # æ•°æ®æº 1 â€” æœ¬åœ° docs/ï¼ˆGrep/Glob/Read å¯è¾¾ï¼‰:
    #   - runbook/redis-failover.md (ä¸­æ–‡, Redis Sentinel ä¸»ä»åˆ‡æ¢)
    #   - runbook/kubernetes-pod-crashloop.md (English, CrashLoopBackOff)
    #   - api/authentication.md (ä¸­æ–‡, OAuth 2.0 + JWT)
    #
    # æ•°æ®æº 2 â€” Qdrant ç´¢å¼•ï¼ˆMCP hybrid_search å¯è¾¾ï¼‰:
    #   K8s: 144 docs from kubernetes/website (concepts section)
    #     Pod, Service, Ingress, Deployment, ConfigMap, Secret, Probes,
    #     Volumes, Namespaces, Labels, Nodes, GC, ResourceQuota, etc.
    #   Redis: ~62 docs from redis/docs (official English)
    #     Sentinel, Replication, Persistence, Scaling, Data Types,
    #     Pipelining, Transactions, ACL, Latency, Memory, Debugging, etc.
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    # â”€â”€ A. æœ¬åœ°æ–‡æ¡£ï¼šç²¾ç¡®å…³é”®è¯ï¼ˆGrep ç›´æ¥å‘½ä¸­ï¼‰â”€â”€
    {"id": "local-exact-001",
     "query": "READONLY You can't write against a read only replica è¿™ä¸ªæŠ¥é”™æ€ä¹ˆè§£å†³",
     "category": "redis-failover", "type": "exact", "source": "local",
     "expected_doc": "redis-failover.md",
     "note": "SOé£æ ¼ï¼šè´´é”™è¯¯ä¿¡æ¯æ±‚è§£"},
    {"id": "local-exact-002",
     "query": "kubectl describe pod æ˜¾ç¤º OOMKilled æ€ä¹ˆåŠ",
     "category": "k8s-crashloop", "type": "exact", "source": "local",
     "expected_doc": "kubernetes-pod-crashloop.md",
     "note": "SOé£æ ¼ï¼šè´´å‘½ä»¤è¾“å‡ºæ±‚è§£"},
    {"id": "local-exact-003",
     "query": "API è¿”å› 401 TOKEN_EXPIREDï¼Œå‰ç«¯è¯¥æ€ä¹ˆå¤„ç†",
     "category": "api-auth", "type": "exact", "source": "local",
     "expected_doc": "authentication.md",
     "note": "SOé£æ ¼ï¼šå…·ä½“é”™è¯¯ç "},
    {"id": "local-exact-004",
     "query": "redis-cli SENTINEL get-master-addr-by-name å‘½ä»¤è¿”å›ä»€ä¹ˆ",
     "category": "redis-failover", "type": "exact", "source": "local",
     "expected_doc": "redis-failover.md"},
    {"id": "local-exact-005",
     "query": "JWT RS256 ç­¾åéªŒè¯æµç¨‹æ˜¯ä»€ä¹ˆ",
     "category": "api-auth", "type": "exact", "source": "local",
     "expected_doc": "authentication.md"},

    # â”€â”€ B. æœ¬åœ°æ–‡æ¡£ï¼šStackOverflow çœŸå®åœºæ™¯ï¼ˆç—‡çŠ¶æè¿°ï¼‰â”€â”€
    {"id": "local-so-001",
     "query": "çº¿ä¸Š Redis çªç„¶å¤§é‡å†™å…¥å¤±è´¥ï¼Œé”™è¯¯æ—¥å¿—ä¸€ç›´åˆ·å±ï¼Œåº”ç”¨éƒ½å¿«æŒ‚äº†ï¼Œæ€¥ï¼",
     "category": "redis-failover", "type": "scenario", "source": "local",
     "expected_doc": "redis-failover.md",
     "note": "SOç´§æ€¥æ±‚åŠ©ï¼Œä¸å« READONLY/Sentinel/failover"},
    {"id": "local-so-002",
     "query": "æˆ‘çš„ pod ä¸€ç›´åœ¨ restartï¼Œå·²ç»é‡å¯äº† 50 å¤šæ¬¡äº†ï¼Œdescribe çœ‹äº†ä¹Ÿæ²¡å•¥æœ‰ç”¨ä¿¡æ¯",
     "category": "k8s-crashloop", "type": "scenario", "source": "local",
     "expected_doc": "kubernetes-pod-crashloop.md",
     "note": "SOå£è¯­åŒ–ï¼Œä¸å« CrashLoopBackOff"},
    {"id": "local-so-003",
     "query": "ç”¨æˆ·åé¦ˆè¯´ç™»å½•ä¹‹åè¿‡ä¸€ä¼šå„¿å°±è¢«è¸¢å‡ºæ¥äº†ï¼Œè¦é‡æ–°ç™»å½•ï¼Œæ˜¯ token çš„é—®é¢˜å—",
     "category": "api-auth", "type": "scenario", "source": "local",
     "expected_doc": "authentication.md",
     "note": "SOç”¨æˆ·åé¦ˆï¼Œä¸å« JWT/refresh_token"},
    {"id": "local-so-004",
     "query": "å®¹å™¨è·‘ç€è·‘ç€å°±è¢« kill äº†ï¼Œæ„Ÿè§‰æ˜¯å†…å­˜çš„é—®é¢˜ä½†ä¸ç¡®å®šæ€ä¹ˆæŸ¥",
     "category": "k8s-crashloop", "type": "scenario", "source": "local",
     "expected_doc": "kubernetes-pod-crashloop.md",
     "note": "æ¨¡ç³Šæè¿°â†’OOMKilled"},
    {"id": "local-so-005",
     "query": "Redis ä¸»åº“æŒ‚äº†ä¹‹åä»åº“é¡¶ä¸Šå»äº†ï¼Œä½†æ˜¯åº”ç”¨è¿˜æ˜¯è¿çš„æ—§åœ°å€ï¼Œæ€ä¹ˆè®©åº”ç”¨è‡ªåŠ¨åˆ‡æ¢",
     "category": "redis-failover", "type": "scenario", "source": "local",
     "expected_doc": "redis-failover.md",
     "note": "å£è¯­åŒ–æè¿° failover + Sentinel å®¢æˆ·ç«¯"},
    {"id": "local-so-006",
     "query": "æˆ‘ä»¬æœ‰ä¸ªå¤šç§Ÿæˆ·ç³»ç»Ÿï¼Œä¸åŒç§Ÿæˆ·çš„ç”¨æˆ·ä¸èƒ½äº’ç›¸è®¿é—®æ•°æ®ï¼Œè¿™ä¸ªæƒé™æ€ä¹ˆè®¾è®¡çš„",
     "category": "api-auth", "type": "scenario", "source": "local",
     "expected_doc": "authentication.md",
     "note": "æŒ‡å‘ tenant_id + RBAC"},

    # â”€â”€ C. æœ¬åœ°æ–‡æ¡£ï¼šè·¨è¯­è¨€ â”€â”€
    {"id": "local-cross-001",
     "query": "How to recover when Redis sentinel triggers a failover?",
     "category": "redis-failover", "type": "cross-lang", "source": "local",
     "expected_doc": "redis-failover.md",
     "note": "è‹±æ–‡é—®â†’ä¸­æ–‡æ–‡æ¡£"},
    {"id": "local-cross-002",
     "query": "K8s å®¹å™¨å› ä¸º liveness probe å¤±è´¥ä¸€ç›´é‡å¯æ€ä¹ˆæ’æŸ¥",
     "category": "k8s-crashloop", "type": "cross-lang", "source": "local",
     "expected_doc": "kubernetes-pod-crashloop.md",
     "note": "ä¸­æ–‡é—®â†’è‹±æ–‡æ–‡æ¡£"},

    # â”€â”€ D. æœ¬åœ°æ–‡æ¡£ï¼šHow-to å®æ“ â”€â”€
    {"id": "local-howto-001",
     "query": "æ€ä¹ˆç¡®è®¤ Redis Sentinel å½“å‰çš„ master æ˜¯å“ªä¸ªèŠ‚ç‚¹",
     "category": "redis-failover", "type": "howto", "source": "local",
     "expected_doc": "redis-failover.md"},
    {"id": "local-howto-002",
     "query": "æ€ä¹ˆçœ‹ä¸Šä¸€æ¬¡å®¹å™¨å´©æºƒçš„æ—¥å¿—",
     "category": "k8s-crashloop", "type": "howto", "source": "local",
     "expected_doc": "kubernetes-pod-crashloop.md",
     "note": "æ–‡æ¡£ä¸­æœ‰ kubectl logs --previous"},
    {"id": "local-howto-003",
     "query": "access_token è¿‡æœŸäº†æ€ä¹ˆç»­æœŸï¼Œè°ƒå“ªä¸ªæ¥å£",
     "category": "api-auth", "type": "howto", "source": "local",
     "expected_doc": "authentication.md",
     "note": "æ–‡æ¡£ä¸­æœ‰ /api/v1/auth/refresh"},

    # â”€â”€ E. æœ¬åœ°æ–‡æ¡£ï¼šå¤šæ–‡æ¡£ç»¼åˆ â”€â”€
    {"id": "local-multi-001",
     "query": "Pod é‡å¯å Redis è¿æ¥æ–­äº†ï¼Œä»æ’æŸ¥ Pod åˆ°æ¢å¤ Redis è¿æ¥çš„å®Œæ•´æµç¨‹æ˜¯ä»€ä¹ˆ",
     "category": "multi-doc", "type": "multi-doc", "source": "local",
     "expected_doc": "kubernetes-pod-crashloop.md,redis-failover.md",
     "note": "éœ€è¦ç»¼åˆä¸¤ä¸ª runbook"},

    # â”€â”€ F. Qdrant: Redis å®˜æ–¹æ–‡æ¡£ â”€â”€
    {"id": "qdrant-redis-sentinel-001",
     "query": "How does Redis Sentinel automatic failover work?",
     "category": "redis-sentinel", "type": "concept", "source": "qdrant",
     "expected_doc": "sentinel.md",
     "note": "Official Sentinel doc has full failover explanation"},
    {"id": "qdrant-redis-sentinel-002",
     "query": "Redis Sentinel çš„ quorum æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿæ€ä¹ˆé…ç½®ï¼Ÿ",
     "category": "redis-sentinel", "type": "howto", "source": "qdrant",
     "expected_doc": "sentinel.md",
     "note": "Cross-lang: Chinese question â†’ English doc"},
    {"id": "qdrant-redis-repl-001",
     "query": "Redis master-replica replication æ˜¯å¼‚æ­¥çš„è¿˜æ˜¯åŒæ­¥çš„ï¼Ÿ",
     "category": "redis-replication", "type": "concept", "source": "qdrant",
     "expected_doc": "replication.md"},
    {"id": "qdrant-redis-repl-002",
     "query": "Redis replica æ–­å¼€è¿æ¥åé‡è¿ï¼Œæ˜¯å…¨é‡åŒæ­¥è¿˜æ˜¯éƒ¨åˆ†åŒæ­¥ï¼Ÿ",
     "category": "redis-replication", "type": "scenario", "source": "qdrant",
     "expected_doc": "replication.md"},
    {"id": "qdrant-redis-persist-001",
     "query": "RDB å’Œ AOF æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿè¯¥ç”¨å“ªä¸ªï¼Ÿ",
     "category": "redis-persistence", "type": "concept", "source": "qdrant",
     "expected_doc": "persistence.md"},
    {"id": "qdrant-redis-persist-002",
     "query": "Redis AOF rewrite æ˜¯æ€ä¹ˆå·¥ä½œçš„ï¼Ÿä¼šé˜»å¡ä¸»çº¿ç¨‹å—ï¼Ÿ",
     "category": "redis-persistence", "type": "scenario", "source": "qdrant",
     "expected_doc": "persistence.md"},
    {"id": "qdrant-redis-cluster-001",
     "query": "Redis Cluster çš„ hash slot æ˜¯æ€ä¹ˆåˆ†é…çš„ï¼Ÿ",
     "category": "redis-scaling", "type": "concept", "source": "qdrant",
     "expected_doc": "scaling.md"},
    {"id": "qdrant-redis-strings-001",
     "query": "Redis Strings é™¤äº†ç¼“å­˜è¿˜èƒ½åšä»€ä¹ˆï¼Ÿæ”¯æŒå“ªäº›æ“ä½œï¼Ÿ",
     "category": "redis-strings", "type": "concept", "source": "qdrant",
     "expected_doc": "strings.md"},
    {"id": "qdrant-redis-sorted-set-001",
     "query": "How to implement a leaderboard with Redis Sorted Sets?",
     "category": "redis-sorted-sets", "type": "howto", "source": "qdrant",
     "expected_doc": "sorted-sets.md"},
    {"id": "qdrant-redis-streams-001",
     "query": "Redis Streams å’Œ Pub/Sub æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿä»€ä¹ˆæ—¶å€™ç”¨ Streamsï¼Ÿ",
     "category": "redis-streams", "type": "concept", "source": "qdrant",
     "expected_doc": "streams/_index.md",
     "note": "Streams vs Pub/Sub comparison"},
    {"id": "qdrant-redis-bloom-001",
     "query": "What is a Bloom filter in Redis and when should I use it?",
     "category": "redis-bloom", "type": "concept", "source": "qdrant",
     "expected_doc": "bloom-filter.md"},
    {"id": "qdrant-redis-latency-001",
     "query": "Redis å»¶è¿Ÿçªç„¶å˜é«˜æ€ä¹ˆæ’æŸ¥ï¼Ÿæœ‰å“ªäº›å¸¸è§åŸå› ï¼Ÿ",
     "category": "redis-latency", "type": "scenario", "source": "qdrant",
     "expected_doc": "latency.md"},
    {"id": "qdrant-redis-memory-001",
     "query": "Redis å†…å­˜å ç”¨å¤ªé«˜æ€ä¹ˆä¼˜åŒ–ï¼Ÿ",
     "category": "redis-memory", "type": "scenario", "source": "qdrant",
     "expected_doc": "memory-optimization.md"},
    {"id": "qdrant-redis-acl-001",
     "query": "How to set up Redis ACL to restrict user permissions?",
     "category": "redis-acl", "type": "howto", "source": "qdrant",
     "expected_doc": "acl.md"},
    {"id": "qdrant-redis-pipelining-001",
     "query": "Redis pipelining çš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿå’Œæ™®é€šè¯·æ±‚æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
     "category": "redis-pipelining", "type": "concept", "source": "qdrant",
     "expected_doc": "pipelining.md"},
    {"id": "qdrant-redis-transactions-001",
     "query": "Redis MULTI/EXEC äº‹åŠ¡å’Œ Lua è„šæœ¬å“ªä¸ªæ›´å¥½ï¼Ÿ",
     "category": "redis-transactions", "type": "concept", "source": "qdrant",
     "expected_doc": "transactions.md"},
    {"id": "qdrant-redis-debug-001",
     "query": "çº¿ä¸Š Redis å‡ºé—®é¢˜äº†æ€ä¹ˆ debugï¼Ÿæœ‰å“ªäº›è¯Šæ–­å‘½ä»¤ï¼Ÿ",
     "category": "redis-debugging", "type": "scenario", "source": "qdrant",
     "expected_doc": "debugging.md"},
    {"id": "qdrant-redis-benchmark-001",
     "query": "How to benchmark Redis performance? What tool should I use?",
     "category": "redis-benchmark", "type": "howto", "source": "qdrant",
     "expected_doc": "benchmarks/index.md"},
    {"id": "qdrant-redis-so-001",
     "query": "æˆ‘çš„ Redis ä¸»ä»åŒæ­¥ä¸€ç›´æ–­ï¼Œæ—¥å¿—é‡Œåˆ· LOADING Redis is loading the dataset in memory",
     "category": "redis-replication", "type": "scenario", "source": "qdrant",
     "expected_doc": "replication.md",
     "note": "SO-style: full resync loop problem"},
    {"id": "qdrant-redis-so-002",
     "query": "Redis used_memory æ¯” maxmemory å¤§å¾ˆå¤šï¼Œä½† keys ä¸å¤šï¼Œå†…å­˜å»å“ªäº†ï¼Ÿ",
     "category": "redis-memory", "type": "scenario", "source": "qdrant",
     "expected_doc": "memory-optimization.md",
     "note": "SO-style: memory fragmentation"},

    # â”€â”€ G. Qdrant: K8s å®˜æ–¹æ–‡æ¡£ â”€â”€
    {"id": "qdrant-k8s-pod-001",
     "query": "What is a Pod in Kubernetes?",
     "category": "k8s-pod", "type": "concept", "source": "qdrant",
     "expected_doc": "pods/_index.md"},
    {"id": "qdrant-k8s-service-001",
     "query": "Kubernetes Service æœ‰å“ªäº›ç±»å‹ï¼ŸClusterIP å’Œ NodePort çš„åŒºåˆ«ï¼Ÿ",
     "category": "k8s-service", "type": "concept", "source": "qdrant",
     "expected_doc": "service.md"},
    {"id": "qdrant-k8s-deploy-001",
     "query": "Deployment æ»šåŠ¨æ›´æ–°å¡ä½äº†ï¼Œæ–°æ—§ Pod å¹¶å­˜ï¼Œæ€ä¹ˆå›æ»šï¼Ÿ",
     "category": "k8s-deployment", "type": "scenario", "source": "qdrant",
     "expected_doc": "deployment.md"},
    {"id": "qdrant-k8s-configmap-001",
     "query": "How to use ConfigMap to inject configuration into a Pod?",
     "category": "k8s-configmap", "type": "howto", "source": "qdrant",
     "expected_doc": "configmap.md"},
    {"id": "qdrant-k8s-secret-001",
     "query": "Kubernetes Secret å’Œ ConfigMap æœ‰ä»€ä¹ˆåŒºåˆ«ï¼ŸSecret å®‰å…¨å—ï¼Ÿ",
     "category": "k8s-secret", "type": "concept", "source": "qdrant",
     "expected_doc": "secret.md"},
    {"id": "qdrant-k8s-probe-001",
     "query": "liveness probe å’Œ readiness probe æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿä»€ä¹ˆæ—¶å€™ç”¨å“ªä¸ªï¼Ÿ",
     "category": "k8s-probes", "type": "concept", "source": "qdrant",
     "expected_doc": "liveness-readiness-startup-probes.md"},
    {"id": "qdrant-k8s-ingress-001",
     "query": "How does Kubernetes Ingress route traffic to different services?",
     "category": "k8s-ingress", "type": "concept", "source": "qdrant",
     "expected_doc": "ingress.md"},
    {"id": "qdrant-k8s-volume-001",
     "query": "Kubernetes é‡Œæ€ä¹ˆç»™ Pod æŒ‚è½½æŒä¹…åŒ–å­˜å‚¨ï¼ŸPV å’Œ PVC çš„å…³ç³»ï¼Ÿ",
     "category": "k8s-volumes", "type": "concept", "source": "qdrant",
     "expected_doc": "volumes.md"},
    {"id": "qdrant-k8s-init-001",
     "query": "What are Init Containers and when should I use them?",
     "category": "k8s-init", "type": "concept", "source": "qdrant",
     "expected_doc": "init-containers.md"},
    {"id": "qdrant-k8s-lifecycle-001",
     "query": "Pod çš„ç”Ÿå‘½å‘¨æœŸæœ‰å“ªäº›é˜¶æ®µï¼ŸPending å’Œ Running çš„åŒºåˆ«ï¼Ÿ",
     "category": "k8s-lifecycle", "type": "concept", "source": "qdrant",
     "expected_doc": "pod-lifecycle.md"},
    {"id": "qdrant-k8s-namespace-001",
     "query": "Kubernetes Namespace æ˜¯ä»€ä¹ˆï¼Ÿä»€ä¹ˆæ—¶å€™éœ€è¦ç”¨å¤šä¸ª Namespaceï¼Ÿ",
     "category": "k8s-namespace", "type": "concept", "source": "qdrant",
     "expected_doc": "namespaces.md"},
    {"id": "qdrant-k8s-label-001",
     "query": "How do Labels and Selectors work in Kubernetes?",
     "category": "k8s-labels", "type": "concept", "source": "qdrant",
     "expected_doc": "labels.md"},
    {"id": "qdrant-k8s-resource-001",
     "query": "æ€ä¹ˆç»™ Pod è®¾ç½® CPU å’Œå†…å­˜çš„ requests å’Œ limitsï¼Ÿ",
     "category": "k8s-resources", "type": "howto", "source": "qdrant",
     "expected_doc": "manage-resources-containers.md"},
    {"id": "qdrant-k8s-node-001",
     "query": "Kubernetes Node çš„çŠ¶æ€æœ‰å“ªäº›ï¼ŸNotReady æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ",
     "category": "k8s-nodes", "type": "concept", "source": "qdrant",
     "expected_doc": "nodes.md"},
    {"id": "qdrant-k8s-gc-001",
     "query": "Kubernetes garbage collection æ˜¯æ€ä¹ˆæ¸…ç†èµ„æºçš„ï¼Ÿ",
     "category": "k8s-gc", "type": "concept", "source": "qdrant",
     "expected_doc": "garbage-collection.md"},
    {"id": "qdrant-k8s-so-001",
     "query": "Pod ä¸€ç›´ Pending ä¸è°ƒåº¦ï¼Œdescribe æ˜¾ç¤º Insufficient cpuï¼Œæ€ä¹ˆåŠï¼Ÿ",
     "category": "k8s-resources", "type": "scenario", "source": "qdrant",
     "expected_doc": "manage-resources-containers.md",
     "note": "SO-style: resource quota issue"},
    {"id": "qdrant-k8s-so-002",
     "query": "Deployment rollout å¡åœ¨ Progressingï¼ŒmaxUnavailable å’Œ maxSurge æ€ä¹ˆè°ƒï¼Ÿ",
     "category": "k8s-deployment", "type": "scenario", "source": "qdrant",
     "expected_doc": "deployment.md"},
    {"id": "qdrant-k8s-so-003",
     "query": "What's the difference between a Deployment and a ReplicationController?",
     "category": "k8s-deploy-vs-rc", "type": "concept", "source": "qdrant",
     "expected_doc": "deployment.md,replicationcontroller.md"},
    {"id": "qdrant-k8s-so-004",
     "query": "Container çš„ preStop hook æ²¡æ‰§è¡Œå°±è¢« kill äº†ï¼Œæ€ä¹ˆä¿è¯ä¼˜é›…é€€å‡ºï¼Ÿ",
     "category": "k8s-lifecycle-hooks", "type": "scenario", "source": "qdrant",
     "expected_doc": "container-lifecycle-hooks.md"},
    {"id": "qdrant-k8s-so-005",
     "query": "LimitRange å’Œ ResourceQuota æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿæ€ä¹ˆé™åˆ¶å•ä¸ª Pod çš„èµ„æºï¼Ÿ",
     "category": "k8s-policy", "type": "concept", "source": "qdrant",
     "expected_doc": "limit-range.md,resource-quotas.md"},

    # â”€â”€ H. æœªæ”¶å½•å†…å®¹ï¼ˆåº”æ˜ç¡®è¯´"æœªæ‰¾åˆ°"ï¼‰â”€â”€
    {"id": "notfound-001",
     "query": "Kubernetes HPA è‡ªåŠ¨æ‰©ç¼©å®¹æ€ä¹ˆé…ç½®",
     "category": "not-in-kb", "type": "notfound", "source": "none",
     "expect_no_results": True,
     "note": "KB æ²¡æœ‰ HPA å†…å®¹"},
    {"id": "notfound-002",
     "query": "MongoDB åˆ†ç‰‡é›†ç¾¤å¦‚ä½•é…ç½®",
     "category": "not-in-kb", "type": "notfound", "source": "none",
     "expect_no_results": True,
     "note": "KB å®Œå…¨æ²¡æœ‰ MongoDB"},
    {"id": "notfound-003",
     "query": "Kafka consumer group rebalance æ€ä¹ˆä¼˜åŒ–ï¼Ÿ",
     "category": "not-in-kb", "type": "notfound", "source": "none",
     "expect_no_results": True,
     "note": "KB æ²¡æœ‰ Kafka å†…å®¹"},
    {"id": "notfound-004",
     "query": "How to set up Prometheus alerting rules?",
     "category": "not-in-kb", "type": "notfound", "source": "none",
     "expect_no_results": True,
     "note": "KB æ²¡æœ‰ Prometheus å†…å®¹"},
    {"id": "notfound-005",
     "query": "Nginx åå‘ä»£ç†é…ç½® upstream è´Ÿè½½å‡è¡¡",
     "category": "not-in-kb", "type": "notfound", "source": "none",
     "expect_no_results": True,
     "note": "KB æ²¡æœ‰ Nginx å†…å®¹"},
    {"id": "notfound-006",
     "query": "MySQL InnoDB æ­»é”æ€ä¹ˆæ’æŸ¥å’Œè§£å†³ï¼Ÿ",
     "category": "not-in-kb", "type": "notfound", "source": "none",
     "expect_no_results": True,
     "note": "KB æ²¡æœ‰ MySQL å†…å®¹"},
    {"id": "notfound-007",
     "query": "Docker Compose å¤šå®¹å™¨ç¼–æ’æ€ä¹ˆé…ç½®ç½‘ç»œï¼Ÿ",
     "category": "not-in-kb", "type": "notfound", "source": "none",
     "expect_no_results": True,
     "note": "KB æ²¡æœ‰ Docker Compose å†…å®¹"},
]

KEYWORD_CHECKS = {
    # æœ¬åœ°æ–‡æ¡£
    "redis-failover": ["redis", "sentinel", "failover", "ä¸»ä»", "åˆ‡æ¢", "master",
                        "readonly", "read only", "è¿æ¥", "æ¢å¤"],
    "k8s-crashloop": ["pod", "crash", "restart", "é‡å¯", "oom", "log", "kubectl",
                       "liveness", "memory", "container"],
    "api-auth": ["token", "jwt", "oauth", "è®¤è¯", "refresh", "rbac", "role",
                  "æƒé™", "401", "login", "ç™»å½•"],
    "multi-doc": ["redis", "pod", "token", "è®¤è¯", "å®‰å…¨", "è¿æ¥", "é‡å¯",
                   "sentinel", "crash", "æƒé™"],
    # Qdrant: Redis å®˜æ–¹æ–‡æ¡£
    "redis-sentinel": ["sentinel", "failover", "master", "replica", "quorum",
                        "monitor", "high availability"],
    "redis-replication": ["replication", "replica", "master", "sync", "resync",
                           "partial", "full", "async", "leader", "follower"],
    "redis-persistence": ["rdb", "aof", "persistence", "snapshot", "append",
                           "rewrite", "fsync", "backup"],
    "redis-scaling": ["cluster", "hash slot", "node", "shard", "scaling"],
    "redis-strings": ["string", "SET", "GET", "counter", "INCR", "cache"],
    "redis-sorted-sets": ["sorted set", "ZADD", "ZRANGE", "score", "rank", "leaderboard"],
    "redis-streams": ["stream", "XADD", "XREAD", "consumer", "group", "message"],
    "redis-bloom": ["bloom", "filter", "probabilistic", "false positive"],
    "redis-latency": ["latency", "slow", "delay", "slowlog", "monitor"],
    "redis-memory": ["memory", "maxmemory", "eviction", "fragmentation", "optimization"],
    "redis-acl": ["acl", "user", "permission", "auth", "password"],
    "redis-pipelining": ["pipeline", "pipelining", "RTT", "batch", "round trip"],
    "redis-transactions": ["MULTI", "EXEC", "transaction", "WATCH", "atomic", "lua"],
    "redis-debugging": ["debug", "crash", "log", "INFO", "MONITOR", "SLOWLOG"],
    "redis-benchmark": ["benchmark", "redis-benchmark", "QPS", "throughput",
                         "performance", "ops"],
    # Qdrant: K8s å®˜æ–¹æ–‡æ¡£
    "k8s-pod": ["pod", "container", "kubernetes", "workload"],
    "k8s-service": ["service", "clusterip", "nodeport", "loadbalancer", "endpoint"],
    "k8s-deployment": ["deployment", "rollout", "rollback", "replica", "update"],
    "k8s-configmap": ["configmap", "configuration", "env", "volume", "mount"],
    "k8s-secret": ["secret", "base64", "opaque", "tls", "password", "sensitive"],
    "k8s-probes": ["liveness", "readiness", "startup", "probe", "health"],
    "k8s-ingress": ["ingress", "service", "host", "path", "rule", "tls"],
    "k8s-volumes": ["volume", "pv", "pvc", "storage", "mount", "persistent"],
    "k8s-init": ["init", "container", "before", "app"],
    "k8s-lifecycle": ["lifecycle", "phase", "pending", "running", "succeeded", "failed"],
    "k8s-namespace": ["namespace", "isolation", "default", "kube-system"],
    "k8s-labels": ["label", "selector", "matchLabels", "annotation", "metadata"],
    "k8s-resources": ["requests", "limits", "cpu", "memory", "resource", "quota"],
    "k8s-nodes": ["node", "NotReady", "condition", "kubelet", "status"],
    "k8s-gc": ["garbage", "collection", "owner", "dependent", "cascading", "finalizer"],
    "k8s-deploy-vs-rc": ["deployment", "replicationcontroller", "replicaset", "replica"],
    "k8s-lifecycle-hooks": ["preStop", "postStart", "hook", "lifecycle", "graceful"],
    "k8s-policy": ["limitrange", "resourcequota", "limit", "quota", "constraint"],
}

# æ˜¯å¦å¯ç”¨ MCPï¼ˆæ¨¡å‹åŠ è½½éœ€è¦ 15-20 åˆ†é’Ÿï¼Œå¯é€‰å…³é—­ï¼‰
USE_MCP = os.environ.get("USE_MCP", "0") == "1"

if USE_MCP:
    BASE_OPTIONS = dict(
        allowed_tools=[
            "Read", "Grep", "Glob", "Bash",
            "mcp__knowledge-base__hybrid_search",
            "mcp__knowledge-base__keyword_search",
            "mcp__knowledge-base__index_status",
        ],
        mcp_servers={
            "knowledge-base": {
                "command": str(PROJECT_ROOT / ".venv" / "bin" / "python"),
                "args": [str(PROJECT_ROOT / "scripts" / "mcp_server.py")],
                "env": {
                    "QDRANT_URL": os.environ.get("QDRANT_URL", "http://localhost:6333"),
                    "COLLECTION_NAME": os.environ.get("COLLECTION_NAME", "knowledge-base"),
                },
            }
        },
        setting_sources=["project"],
        permission_mode="bypassPermissions",
        cwd=str(PROJECT_ROOT),
        max_turns=15,
    )
else:
    # æ—  MCP æ¨¡å¼ï¼šä»…ä½¿ç”¨ Grep/Glob/Readï¼ˆAgentic Layer 1ï¼‰
    # æ³¨æ„ï¼šä¸èƒ½ç”¨ setting_sources=["project"]ï¼Œå¦åˆ™ä¼šåŠ è½½ .mcp.json å¯åŠ¨ MCP server
    # æ”¹ç”¨ system_prompt æ³¨å…¥ CLAUDE.md å’Œ search skill çš„å…³é”®æŒ‡ä»¤
    BASE_OPTIONS = dict(
        allowed_tools=["Read", "Grep", "Glob", "Bash"],
        permission_mode="bypassPermissions",
        cwd=str(PROJECT_ROOT),
        max_turns=15,
        system_prompt="""ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†åº“æ£€ç´¢åŠ©æ‰‹ã€‚ç”¨æˆ·ä¼šç”¨ /search å‘½ä»¤æŸ¥è¯¢çŸ¥è¯†åº“ã€‚

çŸ¥è¯†åº“æ–‡æ¡£åœ¨ docs/ ç›®å½•ä¸‹ï¼Œæ ¼å¼ä¸º Markdownï¼ŒåŒ…å« Kubernetes å’Œ Redis ç›¸å…³æŠ€æœ¯æ–‡æ¡£ã€‚

æ£€ç´¢ç­–ç•¥ï¼š
1. ä½¿ç”¨ Grep æœç´¢å…³é”®è¯
2. ä½¿ç”¨ Glob æŸ¥æ‰¾ç›¸å…³æ–‡ä»¶ï¼ˆå¦‚ docs/**/*.mdï¼‰
3. ä½¿ç”¨ Read è¯»å–å‘½ä¸­æ–‡ä»¶çš„ç›¸å…³æ®µè½
4. ç»¼åˆåˆ†æå¹¶å›ç­”ï¼Œå¿…é¡»å¸¦å¼•ç”¨ [æ¥æº: docs/xxx.md]

å›ç­”è¦æ±‚ï¼š
- åŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹å›ç­”
- å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæ˜ç¡®è¯´æ˜"æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£"
- å›ç­”è¯­è¨€è·ŸéšæŸ¥è¯¢è¯­è¨€ï¼ˆä¸­æ–‡é—®ä¸­æ–‡ç­”ï¼Œè‹±æ–‡é—®è‹±æ–‡ç­”ï¼‰
- å¼•ç”¨å…·ä½“æ–‡æ¡£è·¯å¾„
""",
    )


def log(msg: str, log_file=None):
    """åŒæ—¶è¾“å‡ºåˆ° stdout å’Œæ—¥å¿—æ–‡ä»¶"""
    print(msg, flush=True)
    if log_file:
        log_file.write(msg + "\n")
        log_file.flush()


async def run_query(prompt: str, session_id: Optional[str], log_file) -> Dict[str, Any]:
    """æ‰§è¡Œå•ä¸ªæŸ¥è¯¢ï¼Œå®Œæ•´è®°å½•ä¸­é—´è¿‡ç¨‹"""
    start = time.time()
    answer = ""
    new_session_id = session_id
    cost = 0.0
    num_turns = 0
    tools_used = []
    messages_log = []  # å®Œæ•´æ¶ˆæ¯æ—¥å¿—

    try:
        if session_id:
            opts = ClaudeAgentOptions(
                resume=session_id,
                permission_mode="bypassPermissions",
                max_turns=15,
            )
        else:
            opts = ClaudeAgentOptions(**BASE_OPTIONS)

        async for msg in query(prompt=prompt, options=opts):
            # è®°å½•æ¯æ¡æ¶ˆæ¯çš„å®Œæ•´ä¿¡æ¯
            msg_dict = {}
            for attr in ["type", "subtype", "role", "result", "session_id",
                         "cost_usd", "num_turns", "tool_name", "tool_input",
                         "tool_result", "content", "text", "data",
                         "stop_reason", "duration_ms", "total_cost_usd",
                         "usage", "modelUsage", "permission_denials"]:
                val = getattr(msg, attr, None)
                if val is not None:
                    try:
                        json.dumps(val)  # ç¡®ä¿å¯åºåˆ—åŒ–
                        msg_dict[attr] = val
                    except (TypeError, ValueError):
                        msg_dict[attr] = str(val)

            messages_log.append(msg_dict)

            # è¯¦ç»†æ—¥å¿—è¾“å‡º - è§£æ SDK æ¶ˆæ¯ç»“æ„
            subtype = getattr(msg, "subtype", None)
            content = getattr(msg, "content", None)

            if subtype == "init":
                data = getattr(msg, "data", {}) or {}
                if isinstance(data, dict):
                    new_session_id = data.get("session_id", new_session_id)
                    model = data.get("model", "unknown")
                    log(f"    [INIT] session={new_session_id} model={model}", log_file)
                if hasattr(msg, "session_id"):
                    new_session_id = msg.session_id

            elif subtype == "success":
                # æœ€ç»ˆç»“æœ
                if hasattr(msg, "result"):
                    answer = msg.result if isinstance(msg.result, str) else str(msg.result)
                num_turns = getattr(msg, "num_turns", num_turns)
                cost = getattr(msg, "total_cost_usd", cost) or cost
                duration = getattr(msg, "duration_ms", 0)
                log(f"    [RESULT] {len(answer)} chars | {num_turns} turns | {duration}ms", log_file)

            elif content:
                # è§£æ content blocksï¼ˆTextBlock, ToolUseBlock, ToolResultBlockï¼‰
                if isinstance(content, list):
                    for block in content:
                        block_type = getattr(block, "type", None)
                        if block_type is None and isinstance(block, dict):
                            block_type = block.get("type", "")

                        if block_type == "text" or (hasattr(block, "text") and not hasattr(block, "name") and not hasattr(block, "tool_use_id")):
                            # TextBlock - Claude çš„æ¨ç†/å›å¤
                            text = getattr(block, "text", "") if hasattr(block, "text") else block.get("text", "")
                            if text:
                                # å¤šè¡Œæ–‡æœ¬æˆªæ–­æ˜¾ç¤º
                                lines = text.strip().split("\n")
                                preview = lines[0][:200]
                                if len(lines) > 1:
                                    preview += f" (+{len(lines)-1} lines)"
                                log(f"    [THINK] {preview}", log_file)

                        elif block_type == "tool_use" or hasattr(block, "name"):
                            # ToolUseBlock - å·¥å…·è°ƒç”¨
                            tool_name = getattr(block, "name", "unknown")
                            tool_input = getattr(block, "input", {})
                            if isinstance(tool_input, dict):
                                input_str = json.dumps(tool_input, ensure_ascii=False)
                            else:
                                input_str = str(tool_input)
                            if len(input_str) > 300:
                                input_str = input_str[:300] + "..."
                            log(f"    [TOOL] {tool_name}({input_str})", log_file)
                            tools_used.append(tool_name)

                        elif block_type == "tool_result" or hasattr(block, "tool_use_id"):
                            # ToolResultBlock - å·¥å…·è¿”å›
                            result_content = getattr(block, "content", "")
                            if isinstance(result_content, str):
                                # æˆªæ–­é•¿ç»“æœï¼Œä¿ç•™å…³é”®ä¿¡æ¯
                                lines = result_content.strip().split("\n")
                                if len(lines) > 5:
                                    preview = "\n".join(lines[:3]) + f"\n    ... ({len(lines)} lines total)"
                                else:
                                    preview = result_content[:400]
                                log(f"    [TOOL_OUT] {preview}", log_file)
                            elif isinstance(result_content, list):
                                for rc in result_content:
                                    rc_text = getattr(rc, "text", str(rc)) if hasattr(rc, "text") else str(rc)
                                    log(f"    [TOOL_OUT] {rc_text[:300]}", log_file)

            # æå–å…ƒæ•°æ®
            if hasattr(msg, "cost_usd") and msg.cost_usd:
                cost = msg.cost_usd
            if hasattr(msg, "total_cost_usd") and msg.total_cost_usd:
                cost = msg.total_cost_usd
            if hasattr(msg, "num_turns") and msg.num_turns:
                num_turns = msg.num_turns

            # æ£€æŸ¥ permission denials
            denials = getattr(msg, "permission_denials", None)
            if denials:
                for d in denials:
                    tool = d.get("tool_name", "unknown") if isinstance(d, dict) else str(d)
                    log(f"    [DENIED] {tool}", log_file)

        elapsed = time.time() - start
        return {
            "status": "success",
            "answer": answer,
            "session_id": new_session_id,
            "elapsed": elapsed,
            "cost_usd": cost,
            "num_turns": num_turns,
            "tools_used": tools_used,
            "messages_log": messages_log,
        }
    except Exception as e:
        elapsed = time.time() - start
        log(f"    [ERROR] {e}", log_file)
        return {
            "status": "error",
            "error": str(e),
            "session_id": new_session_id,
            "elapsed": elapsed,
            "messages_log": messages_log,
        }


def evaluate(tc: Dict, result: Dict) -> Dict:
    """ä¸¤é˜¶æ®µè¯„ä¼°: Gate é—¨ç¦ (ç¡®å®šæ€§) â†’ å…³é”®è¯è´¨é‡æ£€æŸ¥ (è¾…åŠ©)ã€‚"""
    ev = {"passed": False, "reasons": [], "quality": {}, "gate": {}}

    if result["status"] != "success":
        ev["reasons"].append(f"æ‰§è¡Œå¤±è´¥: {result.get('error', '')[:80]}")
        return ev

    answer = result.get("answer", "")
    messages_log = result.get("messages_log", [])

    # â”€â”€ Stage 1: ç»“æ„åŒ– context æå– â”€â”€
    contexts = extract_contexts(messages_log)
    ev["quality"]["contexts_count"] = len(contexts)
    ev["quality"]["tools_used"] = get_tools_used(contexts)
    ev["quality"]["retrieved_paths"] = get_retrieved_doc_paths(contexts)

    # â”€â”€ Stage 2: Gate é—¨ç¦ â”€â”€
    gate = gate_check(tc, answer, contexts)
    ev["gate"] = gate

    if not gate["passed"]:
        ev["passed"] = False
        ev["reasons"] = gate["reasons"]
        return ev

    # â”€â”€ Stage 3: è´¨é‡æ£€æŸ¥ (Gate é€šè¿‡åçš„è¾…åŠ©æŒ‡æ ‡) â”€â”€
    if len(answer) < 50:
        ev["reasons"].append(f"ç­”æ¡ˆè¿‡çŸ­ ({len(answer)})")
        return ev

    # å¼•ç”¨è´¨é‡ (ä» gate è·å–)
    ev["quality"]["has_citation"] = gate["checks"].get("has_citation", False)

    # å…³é”®è¯åŒ¹é… (è¾…åŠ©ä¿¡å·ï¼Œä¸ä½œä¸º pass/fail åˆ¤æ®)
    expected = KEYWORD_CHECKS.get(tc["category"], [])
    matched = [k for k in expected if k.lower() in answer.lower()]
    ev["quality"]["keywords"] = matched

    # æ­£ç¡®æ–‡æ¡£å¼•ç”¨ (ä» gate çš„ expected_doc_hit è·å–)
    ev["quality"]["correct_doc"] = gate["checks"].get("expected_doc_hit", None)

    # Gate é€šè¿‡ + ç­”æ¡ˆè¶³å¤Ÿé•¿ â†’ é€šè¿‡
    if len(answer) >= 50:
        ev["passed"] = True
    else:
        ev["reasons"].append(f"ç­”æ¡ˆè¿‡çŸ­ ({len(answer)})")

    return ev


async def main():
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_dir = PROJECT_ROOT / "eval" / "logs"
    log_dir.mkdir(parents=True, exist_ok=True)
    log_path = log_dir / f"agentic_rag_{timestamp}.log"
    detail_path = log_dir / f"agentic_rag_{timestamp}_detail.jsonl"

    with open(log_path, "w", encoding="utf-8") as lf, \
         open(detail_path, "w", encoding="utf-8") as df:

        mode = "MCP + Grep/Glob/Read" if USE_MCP else "Grep/Glob/Read (æ—  MCP)"
        kb_commit_header = get_kb_commit()
        log("=" * 80, lf)
        log(f"ğŸ¤– Agentic RAG æµ‹è¯• (Agent SDK)", lf)
        log("=" * 80, lf)
        log(f"ç”¨ä¾‹: {len(TEST_CASES)} | æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", lf)
        log(f"æ¨¡å¼: {mode}", lf)
        log(f"KB commit: {kb_commit_header}", lf)
        log(f"è¯„ä¼°: eval_module (Gate é—¨ç¦ + è´¨é‡æ£€æŸ¥)", lf)
        log(f"ç­–ç•¥: Claude è‡ªä¸»é€‰æ‹©æ£€ç´¢ç­–ç•¥ (Grep/Glob/Read{' + MCP hybrid_search' if USE_MCP else ''})", lf)
        log(f"æ—¥å¿—: {log_path}", lf)
        log(f"è¯¦ç»†: {detail_path}", lf)
        log("", lf)

        results = []
        passed = failed = errors = 0
        total_time = total_cost = 0.0
        session_id = None

        for i, tc in enumerate(TEST_CASES, 1):
            log(f"\n{'='*60}", lf)
            log(f"[{i}/{len(TEST_CASES)}] {tc['id']} ({tc['category']}) [{tc.get('type', '?')}]", lf)
            log(f"  Q: {tc['query']}", lf)
            if tc.get("note"):
                log(f"  ğŸ’¡ {tc['note']}", lf)
            if i == 1:
                log(f"  â³ é¦–æ¬¡æŸ¥è¯¢ï¼ŒåŠ è½½ MCP server (BGE-M3)...", lf)
            log(f"  å¼€å§‹: {datetime.now().strftime('%H:%M:%S')}", lf)

            # å¦‚æœæœ‰ MCP + skillsï¼Œç”¨ /searchï¼›å¦åˆ™ç›´æ¥æé—®
            prompt = f"/search {tc['query']}" if USE_MCP else f"è¯·åœ¨ docs/ ç›®å½•ä¸­æ£€ç´¢å¹¶å›ç­”: {tc['query']}"
            result = await run_query(prompt, session_id, lf)

            if result.get("session_id"):
                session_id = result["session_id"]
                if i == 1:
                    log(f"  ğŸ“Œ Session: {session_id}", lf)

            elapsed = result.get("elapsed", 0)
            total_time += elapsed
            total_cost += result.get("cost_usd", 0)

            ev = evaluate(tc, result)

            if result["status"] == "error":
                log(f"  âŒ é”™è¯¯: {result.get('error', '')[:80]}", lf)
                errors += 1
                status = "error"
            elif ev["passed"]:
                ans_len = len(result.get("answer", ""))
                quality = ev.get("quality", {})
                tools = quality.get("tools_used", [])
                cite = "å¼•ç”¨âœ…" if quality.get("has_citation") else "å¼•ç”¨âŒ"
                correct_doc = quality.get("correct_doc")
                doc_tag = "æ–‡æ¡£âœ…" if correct_doc else ("æ–‡æ¡£âŒ" if correct_doc is False else "")
                ctx_count = quality.get("contexts_count", 0)
                kw = quality.get("keywords", [])
                log(f"  âœ… é€šè¿‡ | {ans_len}å­—ç¬¦ | {elapsed:.1f}s | ${result.get('cost_usd', 0):.4f} | {cite} {doc_tag} | ctx:{ctx_count}", lf)
                if tools:
                    log(f"  ğŸ”§ å·¥å…·: {', '.join(tools)}", lf)
                if quality.get("retrieved_paths"):
                    log(f"  ğŸ“„ æ£€ç´¢: {', '.join(quality['retrieved_paths'][:5])}", lf)
                if kw:
                    log(f"  ğŸ”‘ å…³é”®è¯: {', '.join(kw)}", lf)
                passed += 1
                status = "passed"
            else:
                log(f"  âŒ å¤±è´¥: {'; '.join(ev['reasons'])}", lf)
                failed += 1
                status = "failed"

            # è¾“å‡ºç­”æ¡ˆé¢„è§ˆï¼ˆé€šè¿‡å’Œå¤±è´¥éƒ½è¾“å‡ºï¼‰
            ans_preview = result.get("answer", "")[:500]
            if ans_preview:
                log(f"  ğŸ“ ç­”æ¡ˆ: {ans_preview}{'...' if len(result.get('answer',''))>500 else ''}", lf)

            log(f"  ç»“æŸ: {datetime.now().strftime('%H:%M:%S')} | è€—æ—¶: {elapsed:.1f}s", lf)

            # å†™å…¥è¯¦ç»† JSONLï¼ˆæ¯ä¸ª query ä¸€è¡Œï¼ŒåŒ…å«å®Œæ•´æ¶ˆæ¯æ—¥å¿—ï¼‰
            gate = ev.get("gate", {})
            quality = ev.get("quality", {})
            detail_record = {
                "test_id": tc["id"],
                "category": tc["category"],
                "type": tc.get("type", "unknown"),
                "source": tc.get("source", "unknown"),
                "query": tc["query"],
                "status": status,
                "elapsed_seconds": elapsed,
                "cost_usd": result.get("cost_usd", 0),
                "num_turns": result.get("num_turns", 0),
                "answer_length": len(result.get("answer", "")),
                "answer": result.get("answer", ""),
                "tools_used": quality.get("tools_used", []),
                "retrieved_paths": quality.get("retrieved_paths", []),
                "contexts_count": quality.get("contexts_count", 0),
                "has_citation": quality.get("has_citation", False),
                "correct_doc": quality.get("correct_doc"),
                "matched_keywords": quality.get("keywords", []),
                "gate_passed": gate.get("passed"),
                "gate_checks": gate.get("checks", {}),
                "failure_reasons": ev.get("reasons", []),
                "messages": result.get("messages_log", []),
            }
            df.write(json.dumps(detail_record, ensure_ascii=False) + "\n")
            df.flush()

            results.append({
                "test_id": tc["id"], "category": tc["category"],
                "type": tc.get("type", "unknown"),
                "source": tc.get("source", "unknown"),
                "query": tc["query"],
                "status": status, "elapsed_seconds": elapsed,
                "cost_usd": result.get("cost_usd", 0),
                "num_turns": result.get("num_turns", 0),
                "answer_length": len(result.get("answer", "")),
                "tools_used": quality.get("tools_used", []),
                "retrieved_paths": quality.get("retrieved_paths", []),
                "contexts_count": quality.get("contexts_count", 0),
                "has_citation": quality.get("has_citation", False),
                "correct_doc": quality.get("correct_doc"),
                "matched_keywords": quality.get("keywords", []),
                "gate_passed": gate.get("passed"),
                "failure_reasons": ev.get("reasons", []),
                "answer_preview": result.get("answer", "")[:300],
            })
            log("-" * 80, lf)

        # æ€»ç»“
        total = len(TEST_CASES)
        log(f"\n{'=' * 80}", lf)
        log(f"ğŸ“Š æ€»ç»“: âœ…{passed} âŒ{failed} âš ï¸{errors} / {total} ({passed/total*100:.1f}%)", lf)
        log(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f}s | å¹³å‡: {total_time/max(passed+failed,1):.1f}s", lf)
        log(f"ğŸ’° æ€»è´¹ç”¨: ${total_cost:.4f}", lf)

        # æŒ‰æŸ¥è¯¢ç±»å‹ç»Ÿè®¡
        type_stats = {}
        for i2, r in enumerate(results):
            qtype = TEST_CASES[i2].get("type", "unknown")
            type_stats.setdefault(qtype, {"t": 0, "p": 0})
            type_stats[qtype]["t"] += 1
            if r["status"] == "passed": type_stats[qtype]["p"] += 1

        log("", lf)
        log("ğŸ“ˆ æŒ‰æŸ¥è¯¢ç±»å‹:", lf)
        type_labels = {
            "exact": "ç²¾ç¡®åŒ¹é…(Grepæ“…é•¿)",
            "scenario": "SOåœºæ™¯/ç—‡çŠ¶æè¿°",
            "cross-lang": "è·¨è¯­è¨€",
            "howto": "å®æ“é—®ç­”",
            "multi-doc": "å¤šæ–‡æ¡£ç»¼åˆ",
            "concept": "æ¦‚å¿µå‹(éœ€Qdrant)",
            "notfound": "æœªæ”¶å½•",
        }
        for t, s in sorted(type_stats.items()):
            r2 = s["p"]/s["t"]*100
            label = type_labels.get(t, t)
            log(f"  {'âœ…' if r2==100 else 'âš ï¸' if r2>0 else 'âŒ'} {label}: {s['p']}/{s['t']} ({r2:.0f}%)", lf)

        log("", lf)
        log("ğŸ“‹ æŒ‰ category:", lf)
        cats = {}
        for r in results:
            c = r["category"]
            cats.setdefault(c, {"t": 0, "p": 0})
            cats[c]["t"] += 1
            if r["status"] == "passed": cats[c]["p"] += 1
        for c, s in sorted(cats.items()):
            r2 = s["p"]/s["t"]*100
            log(f"  {'âœ…' if r2==100 else 'âš ï¸' if r2>0 else 'âŒ'} {c}: {s['p']}/{s['t']} ({r2:.0f}%)", lf)

        # æŒ‰æ•°æ®æºç»Ÿè®¡
        source_stats = {}
        for i2, r in enumerate(results):
            src = TEST_CASES[i2].get("source", "unknown")
            source_stats.setdefault(src, {"t": 0, "p": 0})
            source_stats[src]["t"] += 1
            if r["status"] == "passed": source_stats[src]["p"] += 1

        log("", lf)
        log("ğŸ—„ï¸ æŒ‰æ•°æ®æº:", lf)
        source_labels = {
            "local": "æœ¬åœ° docs/ (Grep/Glob/Read)",
            "qdrant": "Qdrant ç´¢å¼• (éœ€ MCP hybrid_search)",
        }
        for src, s in sorted(source_stats.items()):
            r2 = s["p"]/s["t"]*100
            label = source_labels.get(src, src)
            icon = "âœ…" if r2 == 100 else ("âš ï¸" if r2 > 0 else "âŒ")
            log(f"  {icon} {label}: {s['p']}/{s['t']} ({r2:.0f}%)", lf)

        if not USE_MCP and source_stats.get("qdrant", {}).get("t", 0) > 0:
            qdrant_total = source_stats["qdrant"]["t"]
            qdrant_pass = source_stats["qdrant"]["p"]
            log(f"\n  âš ï¸  æ³¨æ„: {qdrant_total} ä¸ª Qdrant ç”¨ä¾‹åœ¨æ—  MCP æ¨¡å¼ä¸‹è¿è¡Œ", lf)
            log(f"     é€šè¿‡ {qdrant_pass}/{qdrant_total} â€” å¯èƒ½æ˜¯ Claude ç”¨é€šç”¨çŸ¥è¯†å›ç­”ï¼ˆéæ£€ç´¢ï¼‰", lf)
            log(f"     è®¾ç½® USE_MCP=1 å¯ç”¨ hybrid_search ä»¥æµ‹è¯•çœŸæ­£çš„å‘é‡æ£€ç´¢", lf)

        # ä¿å­˜æ±‡æ€» JSON
        kb_commit = get_kb_commit()
        out_dir = PROJECT_ROOT / "eval"
        out_file = out_dir / f"agentic_rag_test_{timestamp}.json"
        with open(out_file, "w", encoding="utf-8") as f:
            json.dump({
                "timestamp": datetime.now().isoformat(), "test_type": "agentic_rag",
                "method": "claude_agent_sdk_session_reuse", "total": total,
                "passed": passed, "failed": failed, "errors": errors,
                "total_time": total_time, "total_cost": total_cost,
                "kb_commit": kb_commit,
                "eval_module": "eval_module.py (gate + quality)",
                "type_stats": {t: {"total": s["t"], "passed": s["p"]} for t, s in type_stats.items()},
                "source_stats": {s: {"total": v["t"], "passed": v["p"]} for s, v in source_stats.items()},
                "use_mcp": USE_MCP,
                "results": results,
            }, f, indent=2, ensure_ascii=False)

        log(f"\nğŸ“ æ±‡æ€»: {out_file}", lf)
        log(f"ğŸ“‹ æ—¥å¿—: {log_path}", lf)
        log(f"ğŸ“ è¯¦ç»†: {detail_path}", lf)

    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    generate_comparison(str(out_file))
    return results


def generate_comparison(agentic_file: str):
    """ç”Ÿæˆ Simple RAG vs Agentic RAG å¯¹æ¯”"""
    baseline = PROJECT_ROOT / "eval" / "comprehensive_test_20260213_234320.json"
    if not baseline.exists():
        candidates = sorted((PROJECT_ROOT / "eval").glob("comprehensive_test_*.json"))
        if not candidates:
            print("âŒ æœªæ‰¾åˆ° Simple RAG baseline", flush=True)
            return
        baseline = candidates[-1]

    with open(baseline) as f: simple = json.load(f)
    with open(agentic_file) as f: agentic = json.load(f)

    s_map = {r["test_id"]: r for r in simple["results"]}
    a_map = {r["test_id"]: r for r in agentic["results"]}
    s_rate = simple["passed"]/simple["total"]*100
    a_rate = agentic["passed"]/agentic["total"]*100
    s_avg = simple.get("total_time",0)/simple["total"]
    a_avg = agentic.get("total_time",0)/agentic["total"]

    improved = [t for t in TEST_CASES if s_map.get(t["id"],{}).get("status")!="passed" and a_map.get(t["id"],{}).get("status")=="passed"]
    regressed = [t for t in TEST_CASES if s_map.get(t["id"],{}).get("status")=="passed" and a_map.get(t["id"],{}).get("status")!="passed"]

    report = f"""# Simple RAG vs Agentic RAG å¯¹æ¯”æŠ¥å‘Š

**æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | **æ–¹æ³•**: Claude Agent SDK + Session å¤ç”¨

## ğŸ“Š æ€»ä½“

| æŒ‡æ ‡ | Simple RAG | Agentic RAG | å˜åŒ– |
|------|-----------|-------------|------|
| é€šè¿‡ç‡ | {simple['passed']}/{simple['total']} ({s_rate:.1f}%) | {agentic['passed']}/{agentic['total']} ({a_rate:.1f}%) | **{a_rate-s_rate:+.1f}%** |
| å¤±è´¥ | {simple['failed']} | {agentic['failed']} | {agentic['failed']-simple['failed']:+d} |
| å¹³å‡è€—æ—¶ | {s_avg:.1f}s | {a_avg:.1f}s | {a_avg-s_avg:+.1f}s |
| è´¹ç”¨ | ~${simple.get('total_tokens',0)*0.000003:.4f} | ${agentic.get('total_cost',0):.4f} | - |

## é€ç”¨ä¾‹

| ID | æŸ¥è¯¢ | Simple | Agentic | |
|----|------|--------|---------|--|
"""
    for tc in TEST_CASES:
        s = "âœ…" if s_map.get(tc["id"],{}).get("status")=="passed" else "âŒ"
        a = "âœ…" if a_map.get(tc["id"],{}).get("status")=="passed" else "âŒ"
        ch = "ğŸŸ¢" if s=="âŒ" and a=="âœ…" else "ğŸ”´" if s=="âœ…" and a=="âŒ" else ""
        q = tc["query"][:35]+"..." if len(tc["query"])>35 else tc["query"]
        report += f"| {tc['id']} | {q} | {s} | {a} | {ch} |\n"

    if improved:
        report += f"\n## ğŸŸ¢ æ”¹å–„ ({len(improved)})\n\n"
        for tc in improved:
            a = a_map.get(tc["id"],{})
            report += f"- **{tc['id']}**: {tc['query']} â†’ {a.get('answer_length',0)}å­—ç¬¦, å·¥å…·: {', '.join(a.get('tools_used',[]))}\n"

    if regressed:
        report += f"\n## ğŸ”´ é€€æ­¥ ({len(regressed)})\n\n"
        for tc in regressed:
            a = a_map.get(tc["id"],{})
            report += f"- **{tc['id']}**: {tc['query']} â†’ {'; '.join(a.get('failure_reasons',[]))}\n"

    report += f"\n## ç»“è®º\n\né€šè¿‡ç‡ {s_rate:.1f}% â†’ {a_rate:.1f}% ({a_rate-s_rate:+.1f}%), æ”¹å–„ {len(improved)} ä¸ª, é€€æ­¥ {len(regressed)} ä¸ªã€‚\n"

    rf = PROJECT_ROOT / "eval" / f"AGENTIC_VS_SIMPLE_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    with open(rf, "w", encoding="utf-8") as f: f.write(report)
    print(f"ğŸ“Š æŠ¥å‘Š: {rf}", flush=True)


if __name__ == "__main__":
    asyncio.run(main())
