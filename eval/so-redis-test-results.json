[
  {
    "id": "so-001",
    "question": "I'm building a Python app that needs to execute ~5000 Redis SET commands to update user session data. I've read about both pipelining and MULTI/EXEC transactions but I'm confused about the difference. Pipelining seems to batch commands to reduce RTT, while MULTI/EXEC provides atomicity. Can I use both together? When should I choose one over the other? My main concern is throughput, not atomicity.",
    "source": "stackoverflow.com/questions/29327544",
    "expected_paths": [
      "using-commands/pipelining",
      "using-commands/transactions",
      "transpipe"
    ],
    "topic": "pipelining",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/nodejs/transpipe.md",
        "title": "Pipelines and transactions",
        "section_path": "Execute a transaction",
        "score": 0.7440803
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/jedis/transpipe.md",
        "title": "Pipelines and transactions",
        "section_path": "Watch keys for changes",
        "score": 0.73529196
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/dotnet/transpipe.md",
        "title": "Pipelines and transactions",
        "section_path": "Watch keys for changes",
        "score": 0.734687
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/redis-py/transpipe.md",
        "title": "Pipelines and transactions",
        "section_path": "Watch keys for changes",
        "score": 0.7198621
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/using-commands/pipelining.md",
        "title": "Redis pipelining",
        "section_path": "It's not just a matter of RTT",
        "score": 0.7091441
      }
    ]
  },
  {
    "id": "so-002",
    "question": "I'm using redis-py in a high-latency network environment (cross-region, ~50ms RTT). Sending 200 individual GET commands takes about 10 seconds. I know pipelining can help reduce round trip time by batching commands, but how exactly does it work under the hood? Does the client buffer all commands and send them in one TCP packet? What happens if the pipeline is very large — is there a risk of filling the TCP buffer?",
    "source": "stackoverflow.com/questions/7929885",
    "expected_paths": [
      "using-commands/pipelining"
    ],
    "topic": "pipelining",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/using-commands/pipelining.md",
        "title": "Redis pipelining",
        "section_path": "Request/Response protocols and round-trip time (RTT)",
        "score": 0.81778646
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/using-commands/pipelining.md",
        "title": "Redis pipelining",
        "section_path": "It's not just a matter of RTT",
        "score": 0.81278
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/using-commands/pipelining.md",
        "title": "Redis pipelining",
        "section_path": "Appendix: Why are busy loops slow even on the loopback interface?",
        "score": 0.74300754
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/hiredis/transpipe.md",
        "title": "Pipelines and transactions",
        "section_path": "Execute a pipeline",
        "score": 0.7383146
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/nodejs/transpipe.md",
        "title": "Pipelines and transactions",
        "section_path": "Execute a transaction",
        "score": 0.7357649
      }
    ]
  },
  {
    "id": "so-003",
    "question": "I have a Redis Sentinel setup with 3 sentinels and 1 master + 2 replicas on CentOS 7. When I stop the master with `redis-cli -p 6379 DEBUG SLEEP 60`, the sentinels detect +sdown but never reach +odown and no failover happens. My sentinel config has `sentinel monitor mymaster 192.168.1.10 6379 2` with quorum 2. All three sentinels are running and can ping each other. What am I missing? Is it a network or bind address issue?",
    "source": "stackoverflow.com/questions/48579228",
    "expected_paths": [
      "oss_and_stack",
      "sentinel"
    ],
    "topic": "sentinel",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "Sentinel quick start > Configuring Sentinel",
        "score": 0.77547944
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "A quick tutorial > Testing the failover",
        "score": 0.7731117
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "A quick tutorial",
        "score": 0.76393175
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/reference/sentinel-clients.md",
        "title": "Sentinel client spec",
        "section_path": "Redis service discovery via Sentinel",
        "score": 0.7364893
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "Sentinel API > Sentinel commands",
        "score": 0.73547786
      }
    ]
  },
  {
    "id": "so-004",
    "question": "I'm setting up Redis Sentinel for high availability in production with 3 servers. Each server runs both a Redis instance and a Sentinel instance. Server A is master, B and C are replicas. I want automatic failover when the master goes down. What's the recommended sentinel.conf configuration? Specifically: what should the quorum value be for 3 sentinels? Should I set `sentinel down-after-milliseconds` to a low value for faster detection, or will that cause false positives?",
    "source": "stackoverflow.com/questions/51524234",
    "expected_paths": [
      "sentinel"
    ],
    "topic": "sentinel",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "Sentinel quick start > Configuring Sentinel",
        "score": 0.8157096
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "Sentinel quick start > Example Sentinel deployments > Example 1: just two Sentinels, DON'T DO THIS",
        "score": 0.79169357
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "Algorithms and internals > Quorum",
        "score": 0.7823317
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "Sentinel quick start > Example Sentinel deployments",
        "score": 0.7736325
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "A quick tutorial",
        "score": 0.7702552
      }
    ]
  },
  {
    "id": "so-005",
    "question": "I'm building a real-time leaderboard for a mobile game with ~100K daily active users. I need to store player scores and quickly retrieve the top 100 players, as well as a specific player's rank. I initially used a Redis List with LPUSH and LRANGE, but updating a player's score requires removing and re-inserting which is O(N). Should I switch to a Sorted Set? What are the time complexity trade-offs between ZADD/ZRANK vs LPUSH/LRANGE for this use case?",
    "source": "stackoverflow.com/questions/48630763",
    "expected_paths": [
      "data-types/sorted-sets",
      "data-types/lists"
    ],
    "topic": "data-types",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/sorted-sets.md",
        "title": "Redis sorted sets",
        "section_path": "Learn more",
        "score": 0.7065691
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/sorted-sets.md",
        "title": "Redis sorted sets",
        "section_path": "Lexicographical scores",
        "score": 0.6881833
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/sorted-sets.md",
        "title": "Redis sorted sets",
        "section_path": "",
        "score": 0.6764546
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/whats-new/7-2.md",
        "title": "Redis 7.2",
        "section_path": "Improvements > Client and replication enhancements",
        "score": 0.63690794
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/agent-builder/agent-concepts.md",
        "title": "agent-concepts.md",
        "section_path": "Redis data structures for agent memory > Redis Sorted Sets for Rankings and Priorities",
        "score": 0.6338122
      }
    ]
  },
  {
    "id": "so-006",
    "question": "I'm trying to understand Redis internals for a systems design interview. I know Redis has Strings, Lists, Sets, Sorted Sets, and Hashes as user-facing data types, but what data structures does Redis actually use internally? For example, I've heard that small Lists use a ziplist encoding while larger ones use a linked list. What are the underlying data structures for each type, and when does Redis switch between encodings?",
    "source": "stackoverflow.com/questions/9625246",
    "expected_paths": [
      "data-types"
    ],
    "topic": "data-types",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/_index.md",
        "title": "Redis data types",
        "section_path": "Data types",
        "score": 0.75213635
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/optimization/memory-optimization.md",
        "title": "Memory optimization",
        "section_path": "Special encoding of small aggregate data types",
        "score": 0.7404596
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/lists.md",
        "title": "Redis lists",
        "section_path": "Examples > What are Lists?",
        "score": 0.71818435
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/compare-data-types.md",
        "title": "Compare data types",
        "section_path": "Data type features",
        "score": 0.7110485
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/search-and-query/administration/overview.md",
        "title": "Technical overview",
        "section_path": "Data structures > Inverted index",
        "score": 0.702518
      }
    ]
  },
  {
    "id": "so-007",
    "question": "I need to store user profile data in Redis. Each user has fields like name, email, age, and preferences. I'm debating between using a Redis Hash (HSET user:123 name 'John' email 'john@example.com') vs a Redis Set for storing unique attributes. When should I use a Hash vs a Set? Also, I've seen people mention Redis JSON as an alternative — how does that compare to Hashes for structured data?",
    "source": "stackoverflow.com/questions/13557075",
    "expected_paths": [
      "data-types/sets",
      "data-types/hashes",
      "hash_vs_json"
    ],
    "topic": "data-types",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.11.1/user_guide/hash_vs_json.md",
        "title": "Hash vs JSON Storage",
        "section_path": "Hash or JSON -- how to choose?",
        "score": 0.75740445
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.12.1/user_guide/hash_vs_json.md",
        "title": "Hash vs JSON Storage",
        "section_path": "Hash or JSON -- how to choose?",
        "score": 0.75740445
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.12.0/user_guide/hash_vs_json.md",
        "title": "Hash vs JSON Storage",
        "section_path": "Hash or JSON -- how to choose?",
        "score": 0.75740445
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/user_guide/hash_vs_json.md",
        "title": "Hash vs JSON Storage",
        "section_path": "Hash or JSON -- how to choose?",
        "score": 0.75740445
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.6.0/user_guide/hash_vs_json.md",
        "title": "Hash vs JSON Storage",
        "section_path": "Hash or JSON -- how to choose?",
        "score": 0.7540776
      }
    ]
  },
  {
    "id": "so-008",
    "question": "I'm running Redis in production as a primary data store (not just cache) and need to configure persistence. I understand there are two options: RDB snapshots and AOF (Append Only File). RDB creates point-in-time snapshots at intervals, while AOF logs every write operation. My concern is data loss — with RDB, I could lose up to 5 minutes of data if Redis crashes between snapshots. But AOF seems to have performance overhead. Can I use both together? What's the recommended setup for production where I need both performance and minimal data loss?",
    "source": "stackoverflow.com/questions/39953542",
    "expected_paths": [
      "oss_and_stack",
      "persistence"
    ],
    "topic": "persistence",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
        "title": "Redis persistence",
        "section_path": "RDB disadvantages",
        "score": 0.84702873
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.4/databases/configure/database-persistence.md",
        "title": "database-persistence.md",
        "section_path": "Active-Active data persistence",
        "score": 0.84501195
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.8/databases/configure/database-persistence.md",
        "title": "database-persistence.md",
        "section_path": "Active-Active data persistence",
        "score": 0.84501195
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.22/databases/configure/database-persistence.md",
        "title": "database-persistence.md",
        "section_path": "Active-Active data persistence",
        "score": 0.84501195
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/databases/configure/database-persistence.md",
        "title": "database-persistence.md",
        "section_path": "Active-Active data persistence",
        "score": 0.8429028
      }
    ]
  },
  {
    "id": "so-009",
    "question": "I'm looking at my Redis AOF file and noticed it starts with the string 'REDIS' followed by binary data, which looks like an RDB preamble. Then the rest of the file has the normal AOF command format (*2\\r\\n$6\\r\\nSELECT...). Is the AOF file actually a mix of RDB and AOF format? When did Redis start doing this? I'm on Redis 7.0 and trying to understand the file format for a backup tool I'm building.",
    "source": "stackoverflow.com/questions/73415771",
    "expected_paths": [
      "persistence"
    ],
    "topic": "persistence",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
        "title": "Redis persistence",
        "section_path": "Backing up Redis data > Backing up AOF persistence",
        "score": 0.7254991
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
        "title": "Redis persistence",
        "section_path": "Append-only file > What should I do if my AOF gets corrupted?",
        "score": 0.7153235
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
        "title": "Redis persistence",
        "section_path": "Backing up Redis data",
        "score": 0.7092024
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
        "title": "Redis persistence",
        "section_path": "Append-only file",
        "score": 0.7068485
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
        "title": "Redis persistence",
        "section_path": "AOF disadvantages",
        "score": 0.7022921
      }
    ]
  },
  {
    "id": "so-010",
    "question": "I stored about 500MB of string data in Redis (verified by summing the sizes of all values), but `INFO memory` shows `used_memory_human: 4.8G` — almost 10x more than my actual data. I'm using Redis 6.2 on Linux with jemalloc. I understand there's some overhead for data structures, but 10x seems excessive. Running `MEMORY DOCTOR` says 'Sam, I have a few things to report' and mentions high fragmentation ratio. What's causing this and how can I reduce memory usage?",
    "source": "stackoverflow.com/questions/10004565",
    "expected_paths": [
      "oss_and_stack",
      "memory"
    ],
    "topic": "memory",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/optimization/memory-optimization.md",
        "title": "Memory optimization",
        "section_path": "Memory allocation",
        "score": 0.71723664
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.22/references/metrics/resource-usage.md",
        "title": "resource-usage.md",
        "section_path": "Memory > Memory usage",
        "score": 0.7168386
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/references/metrics/resource-usage.md",
        "title": "resource-usage.md",
        "section_path": "Memory > Memory usage",
        "score": 0.7168386
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.8/references/metrics/resource-usage.md",
        "title": "resource-usage.md",
        "section_path": "Memory > Memory usage",
        "score": 0.7168386
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.4/references/metrics/resource-usage.md",
        "title": "resource-usage.md",
        "section_path": "Memory > Memory usage",
        "score": 0.7168386
      }
    ]
  },
  {
    "id": "so-011",
    "question": "I'm running Redis as a session cache with `maxmemory 2gb` and `maxmemory-policy volatile-lru`. Today I noticed Redis is using 2.3GB according to `INFO memory`, which exceeds my maxmemory setting. I thought maxmemory was a hard limit? Also, some keys without TTL are being evicted even though I set volatile-lru (which should only evict keys with an expire set). What does Redis actually do when it hits the maxmemory limit? Is the eviction policy not working correctly?",
    "source": "stackoverflow.com/questions/5068518",
    "expected_paths": [
      "oss_and_stack",
      "memory"
    ],
    "topic": "memory",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/reference/eviction/index.md",
        "title": "Key eviction",
        "section_path": "Using the `maxmemory` configuration directive {#maxmem}",
        "score": 0.7979998
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/reference/eviction/index.md",
        "title": "Key eviction",
        "section_path": "Eviction policies",
        "score": 0.768484
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/reference/eviction/index.md",
        "title": "Key eviction",
        "section_path": "Using the `maxmemory` configuration directive {#maxmem} > Setting `maxmemory` for a replicated or persisted instance",
        "score": 0.75397706
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/optimization/memory-optimization.md",
        "title": "Memory optimization",
        "section_path": "Memory allocation",
        "score": 0.7514137
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/databases/memory-performance/_index.md",
        "title": "_index.md",
        "section_path": "Auto Tiering",
        "score": 0.7384058
      }
    ]
  },
  {
    "id": "so-012",
    "question": "I just upgraded to Redis 6.0 and want to use the new ACL feature to create separate users for different microservices. Currently everything connects with the default user and `requirepass`. I want to create a user 'analytics' that can only run read commands (GET, MGET, HGETALL) on keys matching 'analytics:*', and another user 'writer' with full access. How do I set this up? Do I use `ACL SETUSER` or edit the ACL file? What's the syntax for key pattern restrictions?",
    "source": "stackoverflow.com/questions/64226667",
    "expected_paths": [
      "security",
      "acl"
    ],
    "topic": "security",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rc/security/access-control/data-access-control/configure-acls.md",
        "title": "configure-acls.md",
        "section_path": "Define permissions with ACL syntax > Advanced capability command permissions",
        "score": 0.78197634
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/acl.md",
        "title": "ACL",
        "section_path": "When ACLs are useful",
        "score": 0.76875275
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rc/security/access-control/data-access-control/configure-acls.md",
        "title": "configure-acls.md",
        "section_path": "Define permissions with ACL syntax",
        "score": 0.76188326
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.22/security/access-control/redis-acl-overview.md",
        "title": "redis-acl-overview.md",
        "section_path": "Redis ACL syntax",
        "score": 0.74894786
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.4/security/access-control/redis-acl-overview.md",
        "title": "redis-acl-overview.md",
        "section_path": "Redis ACL syntax",
        "score": 0.7486796
      }
    ]
  },
  {
    "id": "so-013",
    "question": "I just installed Redis on an Ubuntu server and it's accessible without any authentication. I need to set a password before exposing it to the network. I know I can use `requirepass` in redis.conf, but I have a few questions: 1) Can I set it at runtime with CONFIG SET without restarting? 2) Is requirepass sent in plaintext or is it hashed? 3) Should I also set `bind` to restrict which interfaces Redis listens on? I'm worried about security since I've read about Redis instances being compromised.",
    "source": "stackoverflow.com/questions/7537905",
    "expected_paths": [
      "security"
    ],
    "topic": "security",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/admin.md",
        "title": "Redis administration",
        "section_path": "Redis setup tips > Security",
        "score": 0.7787281
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/_index.md",
        "title": "Redis security",
        "section_path": "TLS support",
        "score": 0.76646113
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/install/archive/install-redis/_index.md",
        "title": "Install Redis",
        "section_path": "Redis persistence",
        "score": 0.7577163
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/_index.md",
        "title": "Redis security",
        "section_path": "Network security",
        "score": 0.74733174
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/_index.md",
        "title": "Redis security",
        "section_path": "Code security",
        "score": 0.74351734
      }
    ]
  },
  {
    "id": "so-014",
    "question": "I need to implement a message queue in Redis for processing background jobs. I've been using Pub/Sub but realized that if a subscriber is disconnected when a message is published, it misses that message entirely — there's no replay or acknowledgment. I heard Redis Streams (XADD/XREAD/XACK) solve this with consumer groups and message persistence. What are the main differences between Pub/Sub and Streams? Is Streams basically a replacement for Pub/Sub, or do they serve different use cases?",
    "source": "stackoverflow.com/questions/59540563",
    "expected_paths": [
      "data-types/streams",
      "pubsub"
    ],
    "topic": "pubsub-streams",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/pubsub/_index.md",
        "title": "Redis Pub/sub",
        "section_path": "Delivery semantics",
        "score": 0.7462894
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/streams/_index.md",
        "title": "Redis Streams",
        "section_path": "Listening for new items with XREAD",
        "score": 0.7176278
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/streams/_index.md",
        "title": "Redis Streams",
        "section_path": "Consumer groups",
        "score": 0.71441203
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/streams/_index.md",
        "title": "Redis Streams",
        "section_path": "Working with multiple consumer groups",
        "score": 0.7080552
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/streams/_index.md",
        "title": "Redis Streams",
        "section_path": "Total latency of consuming a message",
        "score": 0.7070716
      }
    ]
  },
  {
    "id": "so-015",
    "question": "I'm migrating from a single Redis instance to Redis Cluster for horizontal scaling. I understand the cluster uses 16384 hash slots distributed across nodes. When I run a command, Redis computes CRC16(key) % 16384 to determine which slot (and thus which node) handles it. But I'm confused about what happens during resharding — if I add a new node and migrate slots, what happens to in-flight requests? I'm getting MOVED and ASK redirections. What's the difference between MOVED and ASK? Do I need to handle these in my client code?",
    "source": "stackoverflow.com/questions/tagged/redis-cluster",
    "expected_paths": [
      "oss_and_stack",
      "cluster"
    ],
    "topic": "cluster",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/reference/cluster-spec.md",
        "title": "Redis cluster specification",
        "section_path": "Redirection and resharding > MOVED Redirection",
        "score": 0.806797
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/reference/cluster-spec.md",
        "title": "Redis cluster specification",
        "section_path": "Redirection and resharding > ASK redirection",
        "score": 0.80387616
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/reference/cluster-spec.md",
        "title": "Redis cluster specification",
        "section_path": "Redirection and resharding > Live reconfiguration",
        "score": 0.7806641
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/reference/cluster-spec.md",
        "title": "Redis cluster specification",
        "section_path": "Redirection and resharding > Client connections and redirection handling",
        "score": 0.775748
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/scaling.md",
        "title": "Scale with Redis Cluster",
        "section_path": "Create and use a Redis Cluster > Reshard the cluster",
        "score": 0.76950574
      }
    ]
  },
  {
    "id": "so-016",
    "question": "I need high availability for my Redis deployment and I'm confused about whether to use Redis Sentinel or Redis Cluster. My dataset is about 8GB and fits on a single machine. I don't need sharding, just automatic failover. Sentinel seems simpler — it monitors a master-replica setup and promotes a replica if the master fails. But Cluster also provides HA with automatic failover. What's the trade-off? Is Sentinel sufficient if I don't need to shard data, or should I just go with Cluster anyway for future-proofing?",
    "source": "stackoverflow.com/questions/tagged/redis-cluster+redis-sentinel",
    "expected_paths": [
      "oss_and_stack",
      "cluster",
      "sentinel"
    ],
    "topic": "cluster",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "Sentinel as a distributed system",
        "score": 0.77388084
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/reference/sentinel-clients.md",
        "title": "Sentinel client spec",
        "section_path": "Redis service discovery via Sentinel",
        "score": 0.7287581
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "Algorithms and internals > Consistency under partitions",
        "score": 0.7263723
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "Sentinel quick start > Fundamental things to know about Sentinel before deploying",
        "score": 0.7255707
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "Sentinel quick start > Example Sentinel deployments > Example 2: basic setup with three boxes",
        "score": 0.72046065
      }
    ]
  },
  {
    "id": "so-017",
    "question": "I'm setting up Redis replication with 1 master and 2 replicas. During initial sync, I see in the logs that the master is doing a BGSAVE and sending the RDB file to the replica (full synchronization). But after that, it switches to sending just the replication stream. My questions: 1) What triggers a full sync vs partial sync? 2) If a replica disconnects briefly and reconnects, does it always need a full resync? 3) What is the replication backlog buffer and how should I size it to avoid unnecessary full resyncs?",
    "source": "general SO replication questions",
    "expected_paths": [
      "oss_and_stack",
      "replication"
    ],
    "topic": "replication",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/replication.md",
        "title": "Redis replication",
        "section_path": "How Redis replication works",
        "score": 0.75374943
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/replication.md",
        "title": "Redis replication",
        "section_path": "Important facts about Redis replication",
        "score": 0.7440781
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/replication.md",
        "title": "Redis replication",
        "section_path": "",
        "score": 0.7389238
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/replication.md",
        "title": "Redis replication",
        "section_path": "Partial sync after restarts and failovers",
        "score": 0.7145072
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/databases/active-active/syncer.md",
        "title": "syncer.md",
        "section_path": "Syncer process",
        "score": 0.70764256
      }
    ]
  },
  {
    "id": "so-018",
    "question": "I'm new to Redis and trying to connect from a Python application using redis-py. I installed it with `pip install redis` and wrote `r = redis.Redis(host='localhost', port=6379, db=0)` but I'm not sure about connection pooling. The docs mention ConnectionPool but the basic Redis() client seems to work fine. Do I need to explicitly create a connection pool for a web application handling 100+ concurrent requests? Also, should I use `redis.Redis` or `redis.StrictRedis`?",
    "source": "general SO redis-py questions",
    "expected_paths": [
      "clients"
    ],
    "topic": "clients",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/redis-py/connect.md",
        "title": "Connect to the server",
        "section_path": "Retrying connections",
        "score": 0.8036989
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/pools-and-muxing.md",
        "title": "Connection pools and multiplexing",
        "section_path": "Multiplexing",
        "score": 0.77211565
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/ioredis/connect.md",
        "title": "Connect to the server",
        "section_path": "Connect to your production Redis with TLS",
        "score": 0.7305131
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.8/references/connecting-to-redis.md",
        "title": "connecting-to-redis.md",
        "section_path": "Basic connection troubleshooting",
        "score": 0.71441174
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.4/references/connecting-to-redis.md",
        "title": "connecting-to-redis.md",
        "section_path": "Basic connection troubleshooting",
        "score": 0.71441174
      }
    ]
  },
  {
    "id": "so-019",
    "question": "I want to use Redis as a vector database for a RAG (Retrieval Augmented Generation) application. I have ~1M document embeddings (768-dimensional vectors from sentence-transformers) and need to do k-nearest-neighbor similarity search. I see Redis Stack has a vector search module (RediSearch). How do I create a vector index, store embeddings, and query for similar vectors? Is there a Python client like RedisVL that simplifies this? What index types are supported — FLAT vs HNSW?",
    "source": "general SO redis vector questions",
    "expected_paths": [
      "ai",
      "redisvl"
    ],
    "topic": "ai",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/search-and-query/vectors/_index.md",
        "title": "Vector search concepts",
        "section_path": "Create a vector index",
        "score": 0.78107345
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/redis-py/vecsearch.md",
        "title": "Index and query vectors",
        "section_path": "Create the index",
        "score": 0.7735096
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.9.0/_index.md",
        "title": "RedisVL",
        "section_path": "",
        "score": 0.7688718
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.11.1/_index.md",
        "title": "RedisVL",
        "section_path": "",
        "score": 0.7688718
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.8.2/_index.md",
        "title": "RedisVL",
        "section_path": "",
        "score": 0.7688718
      }
    ]
  },
  {
    "id": "so-020",
    "question": "I need to implement a rate limiter in Redis that atomically checks and increments a counter. Using separate GET and INCR commands has a race condition in concurrent scenarios. I know I can use EVAL with a Lua script to make it atomic, but I'm not sure about the syntax. How do I pass keys and arguments to a Lua script via EVAL? Also, what's the difference between EVAL and EVALSHA? Should I use Redis Functions instead of EVAL in Redis 7.0+?",
    "source": "general SO redis lua questions",
    "expected_paths": [
      "programmability"
    ],
    "topic": "scripting",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/programmability/eval-intro.md",
        "title": "Scripting with Lua",
        "section_path": "Getting started",
        "score": 0.7555752
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/programmability/functions-intro.md",
        "title": "Redis functions",
        "section_path": "Prologue (or, what's wrong with Eval Scripts?)",
        "score": 0.71915483
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/programmability/eval-intro.md",
        "title": "Scripting with Lua",
        "section_path": "Script cache",
        "score": 0.7178091
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/programmability/eval-intro.md",
        "title": "Scripting with Lua",
        "section_path": "Script parameterization",
        "score": 0.71123827
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/programmability/_index.md",
        "title": "Redis programmability",
        "section_path": "Running scripts",
        "score": 0.7096139
      }
    ]
  },
  {
    "id": "so-021",
    "question": "I need to enable TLS encryption for Redis connections in production. Our security team requires all data in transit to be encrypted. I'm running Redis 6.2 and I see there's a `tls-port` config option. How do I generate the required certificates (CA cert, server cert, server key) and configure Redis to accept TLS connections? Do I also need to configure the client side? I'm using redis-py and need to pass SSL parameters.",
    "source": "forum.redis.com TLS questions",
    "expected_paths": [
      "security",
      "tls",
      "encryption"
    ],
    "topic": "security",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/php/connect.md",
        "title": "Connect to the server",
        "section_path": "Connect to your production Redis with TLS",
        "score": 0.8181743
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rc/security/database-security/tls-ssl.md",
        "title": "tls-ssl.md",
        "section_path": "Connect over TLS",
        "score": 0.8117618
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/encryption.md",
        "title": "TLS",
        "section_path": "Getting Started > Sentinel",
        "score": 0.798617
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/go/connect.md",
        "title": "Connect to the server",
        "section_path": "Connect to your production Redis with TLS",
        "score": 0.78532714
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rc/security/database-security/tls-ssl.md",
        "title": "tls-ssl.md",
        "section_path": "Connect over TLS > Connect with the Redis CLI > With client authentication",
        "score": 0.7834569
      }
    ]
  },
  {
    "id": "so-022",
    "question": "I want to try Redis Cloud for a new project instead of self-hosting. How do I create a subscription and get a database endpoint? I see there's a free tier. After creating the database, how do I connect to it from my application? Do I need to use TLS? Is there a REST API for managing Redis Cloud subscriptions programmatically?",
    "source": "general SO redis cloud questions",
    "expected_paths": [
      "rc"
    ],
    "topic": "cloud",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/stack-with-enterprise/stack-quickstart.md",
        "title": "Redis Open Source quick start",
        "section_path": "Set up a Redis Cloud database > Connect to the database",
        "score": 0.83713514
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/stack-with-enterprise/stack-quickstart.md",
        "title": "Redis Open Source quick start",
        "section_path": "Set up a Redis Cloud database",
        "score": 0.81000185
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rc/rc-quickstart.md",
        "title": "rc-quickstart.md",
        "section_path": "Connect to a database",
        "score": 0.79134876
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rc/databases/create-database/create-free-database.md",
        "title": "create-free-database.md",
        "section_path": "",
        "score": 0.7781682
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rc/api/examples/create-database.md",
        "title": "create-database.md",
        "section_path": "",
        "score": 0.77512455
      }
    ]
  },
  {
    "id": "so-023",
    "question": "I'm deploying Redis Enterprise on Kubernetes using the Redis Enterprise Operator. I've installed the operator via Helm but I'm confused about the CRDs — there's RedisEnterpriseCluster and RedisEnterpriseDatabase. Do I create the cluster first and then databases inside it? How do I configure persistent storage for the cluster nodes? My K8s cluster uses EBS volumes on AWS. Also, how does the operator handle failover when a pod gets evicted?",
    "source": "general SO redis k8s questions",
    "expected_paths": [
      "kubernetes"
    ],
    "topic": "kubernetes",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/kubernetes/7.4.6/deployment/_index.md",
        "title": "_index.md",
        "section_path": "Compatibility",
        "score": 0.81637263
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/kubernetes/7.4.6/faqs/_index.md",
        "title": "_index.md",
        "section_path": "How should I size Redis Enterprise cluster nodes?",
        "score": 0.8036678
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/kubernetes/7.8.4/faqs/_index.md",
        "title": "_index.md",
        "section_path": "How should I size Redis Enterprise cluster nodes?",
        "score": 0.8036678
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/kubernetes/7.22/deployment/_index.md",
        "title": "_index.md",
        "section_path": "Next steps",
        "score": 0.80185634
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/kubernetes/deployment/_index.md",
        "title": "_index.md",
        "section_path": "Next steps",
        "score": 0.80185634
      }
    ]
  },
  {
    "id": "so-024",
    "question": "I need to store complex nested JSON documents in Redis and query them by nested fields. For example, I have user profiles like `{name: 'John', address: {city: 'NYC', zip: '10001'}, tags: ['premium', 'active']}` and I want to find all users in a specific city. I know Redis has a JSON module (RedisJSON). How do I store JSON with JSON.SET, query nested paths with JSON.GET, and create secondary indexes on nested fields? Should I use JSON or just flatten everything into a Hash?",
    "source": "general SO redis json questions",
    "expected_paths": [
      "data-types/json",
      "hash_vs_json",
      "document-database"
    ],
    "topic": "data-types",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/json/use_cases.md",
        "title": "Use cases",
        "section_path": "",
        "score": 0.7658406
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/user_guide/hash_vs_json.md",
        "title": "Hash vs JSON Storage",
        "section_path": "Working with nested data in JSON > Full JSON Path support",
        "score": 0.7537482
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.12.1/user_guide/hash_vs_json.md",
        "title": "Hash vs JSON Storage",
        "section_path": "Working with nested data in JSON > Full JSON Path support",
        "score": 0.7537482
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.11.0/user_guide/hash_vs_json.md",
        "title": "Hash vs JSON Storage",
        "section_path": "Working with nested data in JSON > Full JSON Path support",
        "score": 0.7537482
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.6.0/user_guide/hash_vs_json.md",
        "title": "Hash vs JSON Storage",
        "section_path": "Working with nested data in JSON > Full JSON Path support",
        "score": 0.7537482
      }
    ]
  },
  {
    "id": "so-025",
    "question": "I want to benchmark my Redis server to establish a performance baseline before deploying to production. I know there's a built-in `redis-benchmark` tool. How do I use it to test specific commands like SET and GET with different payload sizes? I want to test with 100 concurrent connections and 1KB values. Also, the default benchmark uses random keys — can I configure it to use a specific key pattern? What's a reasonable ops/sec to expect on a modern server?",
    "source": "general SO redis benchmark questions",
    "expected_paths": [
      "oss_and_stack",
      "benchmark"
    ],
    "topic": "benchmark",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/optimization/benchmarks/index.md",
        "title": "Redis benchmark",
        "section_path": "Other Redis benchmarking tools",
        "score": 0.7614765
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/optimization/benchmarks/index.md",
        "title": "Redis benchmark",
        "section_path": "How fast is Redis?",
        "score": 0.74603796
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/json/performance/_index.md",
        "title": "Performance",
        "section_path": "",
        "score": 0.7377451
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/clusters/optimize/memtier-benchmark.md",
        "title": "memtier-benchmark.md",
        "section_path": "Populate a database with testing data",
        "score": 0.73726535
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.8/clusters/optimize/memtier-benchmark.md",
        "title": "memtier-benchmark.md",
        "section_path": "Populate a database with testing data",
        "score": 0.73174417
      }
    ]
  },
  {
    "id": "cn-001",
    "question": "我在用 Python 开发一个批量数据导入工具，需要往 Redis 里写入大约 5 万条数据。我看到 Redis 有 pipeline（管道）和 MULTI/EXEC（事务）两种批量执行方式。pipeline 是把多条命令打包发送减少网络往返，而事务是保证原子性执行。这两者能一起用吗？我的场景不需要原子性，只需要高吞吐，应该选哪个？pipeline 一次打包多少条命令比较合适？",
    "source": "SO pipelining vs transaction",
    "expected_paths": [
      "using-commands/pipelining",
      "using-commands/transactions",
      "transpipe"
    ],
    "topic": "pipelining",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/nodejs/transpipe.md",
        "title": "Pipelines and transactions",
        "section_path": "Execute a transaction",
        "score": 0.7651242
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/hiredis/transpipe.md",
        "title": "Pipelines and transactions",
        "section_path": "Execute a pipeline",
        "score": 0.7357634
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/using-commands/pipelining.md",
        "title": "Redis pipelining",
        "section_path": "It's not just a matter of RTT",
        "score": 0.7249416
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/jedis/transpipe.md",
        "title": "Pipelines and transactions",
        "section_path": "Watch keys for changes",
        "score": 0.71810025
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/dotnet/transpipe.md",
        "title": "Pipelines and transactions",
        "section_path": "Watch keys for changes",
        "score": 0.71537185
      }
    ]
  },
  {
    "id": "cn-002",
    "question": "我在 3 台 CentOS 服务器上部署了 Redis Sentinel 哨兵模式，1 主 2 从，每台机器上都跑了一个 sentinel 进程。配置了 `sentinel monitor mymaster 10.0.1.10 6379 2`，quorum 设为 2。但是当我手动 kill 掉 master 进程后，sentinel 日志只显示 +sdown，一直没有触发 +odown 和 failover。三个 sentinel 之间能互相 ping 通。是不是 bind 地址配置有问题？还是 quorum 设置不对？怎么排查主从切换失败？",
    "source": "SO sentinel failover",
    "expected_paths": [
      "sentinel"
    ],
    "topic": "sentinel",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "Sentinel quick start > Configuring Sentinel",
        "score": 0.75166976
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "A quick tutorial",
        "score": 0.74764484
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "A quick tutorial > Testing the failover",
        "score": 0.7373631
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "Sentinel API > Sentinel commands",
        "score": 0.7201766
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
        "title": "High availability with Redis Sentinel",
        "section_path": "Sentinel quick start > Example Sentinel deployments > Example 1: just two Sentinels, DON'T DO THIS",
        "score": 0.7175602
      }
    ]
  },
  {
    "id": "cn-003",
    "question": "我们的 Redis 是作为主数据库使用的（不只是缓存），需要配置持久化防止数据丢失。RDB 是定时快照，AOF 是记录每条写命令。我担心 RDB 模式下如果 Redis 崩溃会丢失两次快照之间的数据（比如 5 分钟）。AOF 的 everysec 策略最多丢 1 秒数据，但听说有性能开销。生产环境应该用哪个？能不能 RDB 和 AOF 同时开启？Redis 7.0 的 AOF 文件格式是不是变了，开头有 RDB 前缀？",
    "source": "SO persistence RDB vs AOF",
    "expected_paths": [
      "persistence"
    ],
    "topic": "persistence",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
        "title": "Redis persistence",
        "section_path": "RDB disadvantages",
        "score": 0.83259964
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
        "title": "Redis persistence",
        "section_path": "AOF disadvantages",
        "score": 0.8323823
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.8/databases/configure/database-persistence.md",
        "title": "database-persistence.md",
        "section_path": "Active-Active data persistence",
        "score": 0.8020519
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.4/databases/configure/database-persistence.md",
        "title": "database-persistence.md",
        "section_path": "Active-Active data persistence",
        "score": 0.8020519
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.22/databases/configure/database-persistence.md",
        "title": "database-persistence.md",
        "section_path": "Active-Active data persistence",
        "score": 0.8020519
      }
    ]
  },
  {
    "id": "cn-004",
    "question": "我的 Redis 实例设置了 `maxmemory 4gb`，淘汰策略是 `volatile-lru`。但是 `INFO memory` 显示 `used_memory` 已经到了 4.6GB，超过了 maxmemory 限制。而且我发现一些没有设置 TTL 的 key 也被淘汰了，volatile-lru 不是应该只淘汰有过期时间的 key 吗？另外，`mem_fragmentation_ratio` 显示 1.8，碎片率很高。怎么优化 Redis 内存占用？maxmemory 到底是硬限制还是软限制？",
    "source": "SO memory optimization",
    "expected_paths": [
      "oss_and_stack",
      "memory"
    ],
    "topic": "memory",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/optimization/memory-optimization.md",
        "title": "Memory optimization",
        "section_path": "Memory allocation",
        "score": 0.7571685
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/reference/eviction/index.md",
        "title": "Key eviction",
        "section_path": "Using the `maxmemory` configuration directive {#maxmem}",
        "score": 0.7357643
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/databases/flash/_index.md",
        "title": "_index.md",
        "section_path": "Next steps",
        "score": 0.72045577
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/databases/memory-performance/_index.md",
        "title": "_index.md",
        "section_path": "Auto Tiering",
        "score": 0.7109237
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/reference/eviction/index.md",
        "title": "Key eviction",
        "section_path": "Eviction policies",
        "score": 0.71053016
      }
    ]
  },
  {
    "id": "cn-005",
    "question": "我们要从单机 Redis 迁移到 Redis Cluster 集群模式。我知道集群用 16384 个哈希槽来分片数据，每个 key 通过 CRC16(key) % 16384 计算属于哪个槽。但我有几个疑问：1) 新加节点后需要手动迁移哈希槽吗？还是自动重新分配？2) 迁移过程中客户端会收到 MOVED 和 ASK 重定向，这两个有什么区别？3) 多 key 操作（如 MGET）在集群模式下是不是不能用了？CROSSSLOT 错误怎么解决？",
    "source": "SO cluster hash slots",
    "expected_paths": [
      "oss_and_stack",
      "cluster"
    ],
    "topic": "cluster",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/reference/cluster-spec.md",
        "title": "Redis cluster specification",
        "section_path": "Redirection and resharding > MOVED Redirection",
        "score": 0.7361196
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/scaling.md",
        "title": "Scale with Redis Cluster",
        "section_path": "Redis Cluster 101 > Redis Cluster master-replica model",
        "score": 0.7343654
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/reference/cluster-spec.md",
        "title": "Redis cluster specification",
        "section_path": "Overview of Redis Cluster main components > Key distribution model",
        "score": 0.72344685
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/reference/cluster-spec.md",
        "title": "Redis cluster specification",
        "section_path": "Redirection and resharding > Live reconfiguration",
        "score": 0.7219384
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/scaling.md",
        "title": "Scale with Redis Cluster",
        "section_path": "Create and use a Redis Cluster > Migrate to Redis Cluster",
        "score": 0.7088151
      }
    ]
  },
  {
    "id": "cn-006",
    "question": "我在做一个手游实时排行榜，日活大概 10 万用户。需要存储玩家分数，快速查询 Top 100 和某个玩家的排名。一开始用 Redis List 存储，但更新分数需要先删除再插入，效率很低。后来看到 Sorted Set 可以用 ZADD 更新分数、ZREVRANK 查排名、ZREVRANGE 取 Top N，时间复杂度都是 O(log N)。Sorted Set 和 List 各自适合什么场景？如果排行榜数据量到千万级别，Sorted Set 还能扛住吗？",
    "source": "SO sorted set vs list",
    "expected_paths": [
      "data-types/sorted-sets",
      "data-types/lists"
    ],
    "topic": "data-types",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/sorted-sets.md",
        "title": "Redis sorted sets",
        "section_path": "Learn more",
        "score": 0.6925373
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/sorted-sets.md",
        "title": "Redis sorted sets",
        "section_path": "Lexicographical scores",
        "score": 0.6772369
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/sorted-sets.md",
        "title": "Redis sorted sets",
        "section_path": "",
        "score": 0.6642462
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/sorted-sets.md",
        "title": "Redis sorted sets",
        "section_path": "Operating on ranges",
        "score": 0.6434752
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/databases/active-active/develop/data-types/sorted-sets.md",
        "title": "sorted-sets.md",
        "section_path": "",
        "score": 0.6422765
      }
    ]
  },
  {
    "id": "cn-007",
    "question": "我需要在 Redis 里实现一个消息队列来处理异步任务。之前用 Pub/Sub 做的，但发现如果消费者断线期间发布的消息会丢失，没有重放机制。而且 Pub/Sub 没有消息确认，消费者处理失败了消息就没了。听说 Redis 5.0 引入的 Streams 支持消费者组、消息持久化和 ACK 确认机制（XADD/XREADGROUP/XACK）。Pub/Sub 和 Streams 的主要区别是什么？Streams 是不是可以完全替代 Pub/Sub？还是各有适用场景？",
    "source": "SO pubsub vs streams",
    "expected_paths": [
      "data-types/streams",
      "pubsub"
    ],
    "topic": "pubsub-streams",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/tools/insight/release-notes/v.2.4.0.md",
        "title": "v.2.4.0.md",
        "section_path": "2.4.0 (June 2022) > Details",
        "score": 0.7359594
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/pubsub/_index.md",
        "title": "Redis Pub/sub",
        "section_path": "Delivery semantics",
        "score": 0.7275042
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/streams/_index.md",
        "title": "Redis Streams",
        "section_path": "Listening for new items with XREAD",
        "score": 0.7088196
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/streams/_index.md",
        "title": "Redis Streams",
        "section_path": "Working with multiple consumer groups",
        "score": 0.7082367
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/streams/_index.md",
        "title": "Redis Streams",
        "section_path": "Removing single items from a stream",
        "score": 0.7040919
      }
    ]
  },
  {
    "id": "cn-008",
    "question": "我们升级到 Redis 6.0 后想用 ACL 功能给不同的微服务分配不同的访问权限。之前所有服务都用同一个 requirepass 密码连接。现在想创建一个只读用户 'readonly' 只能执行 GET/HGETALL 等读命令，访问 'cache:*' 前缀的 key；另一个用户 'admin' 有完全权限。ACL SETUSER 的语法是什么？key 的模式匹配怎么写？能不能限制用户只能访问特定前缀的 key？",
    "source": "SO ACL feature",
    "expected_paths": [
      "security",
      "acl"
    ],
    "topic": "security",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rc/security/access-control/data-access-control/configure-acls.md",
        "title": "configure-acls.md",
        "section_path": "Define permissions with ACL syntax > Advanced capability command permissions",
        "score": 0.8231688
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/acl.md",
        "title": "ACL",
        "section_path": "When ACLs are useful",
        "score": 0.789262
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/acl.md",
        "title": "ACL",
        "section_path": "Configure ACLs with the ACL command",
        "score": 0.77473944
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rc/security/access-control/data-access-control/configure-acls.md",
        "title": "configure-acls.md",
        "section_path": "Define permissions with ACL syntax",
        "score": 0.7743753
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/acl.md",
        "title": "ACL",
        "section_path": "Create and edit user ACLs with the ACL SETUSER command",
        "score": 0.7665728
      }
    ]
  },
  {
    "id": "cn-009",
    "question": "我想用 Redis 做向量相似度搜索，存储大约 100 万条文档的 embedding 向量（768 维，用 sentence-transformers 生成）。需要支持 KNN 查询找最相似的 Top-K 文档。我看到 Redis Stack 有向量搜索功能，支持 FLAT 和 HNSW 两种索引类型。FLAT 是暴力搜索，HNSW 是近似最近邻。100 万条数据应该选哪种？有没有 Python 客户端（比如 RedisVL）可以简化向量索引的创建和查询？",
    "source": "general vector search",
    "expected_paths": [
      "ai",
      "redisvl"
    ],
    "topic": "ai",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/stack-with-enterprise/release-notes/redisearch/redisearch-2.4-release-notes.md",
        "title": "redisearch-2.4-release-notes.md",
        "section_path": "v2.4.3 (March 2022) > What's new in 2.4",
        "score": 0.7013936
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/api/schema.md",
        "title": "Schema",
        "section_path": "Vector Algorithm Comparison > `Migration Considerations`",
        "score": 0.7007544
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.12.1/api/schema.md",
        "title": "Schema",
        "section_path": "Vector Algorithm Comparison > `Migration Considerations`",
        "score": 0.7007544
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.11.0/api/schema.md",
        "title": "Schema",
        "section_path": "Vector Algorithm Comparison > `Migration Considerations`",
        "score": 0.6932192
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.11.1/api/schema.md",
        "title": "Schema",
        "section_path": "Vector Algorithm Comparison > `Migration Considerations`",
        "score": 0.6932192
      }
    ]
  },
  {
    "id": "cn-010",
    "question": "我在搭建 Redis 主从复制，1 主 2 从。初始同步时看到 master 日志在做 BGSAVE 然后把 RDB 文件发给 replica（全量同步）。同步完成后切换到增量的复制流。我的问题是：1) 什么情况下会触发全量同步？什么情况下是增量同步？2) 如果 replica 短暂断开后重连，是不是一定要重新全量同步？3) repl-backlog-size 复制积压缓冲区应该设多大才能避免不必要的全量同步？",
    "source": "SO replication",
    "expected_paths": [
      "oss_and_stack",
      "replication"
    ],
    "topic": "replication",
    "status": "PASS",
    "hits": [
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.4/references/rest-api/objects/bdb/replica_sync.md",
        "title": "replica_sync.md",
        "section_path": "",
        "score": 0.68726814
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.8/references/rest-api/objects/bdb/replica_sync.md",
        "title": "replica_sync.md",
        "section_path": "",
        "score": 0.68726814
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/references/rest-api/objects/bdb/replica_sync.md",
        "title": "replica_sync.md",
        "section_path": "",
        "score": 0.68726814
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.22/references/rest-api/objects/bdb/replica_sync.md",
        "title": "replica_sync.md",
        "section_path": "",
        "score": 0.68726814
      },
      {
        "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/replication.md",
        "title": "Redis replication",
        "section_path": "Important facts about Redis replication",
        "score": 0.68350583
      }
    ]
  }
]