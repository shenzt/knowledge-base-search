{
  "summary": {
    "total": 35,
    "passed": 35,
    "failed": 0,
    "pass_rate": 100.0,
    "top_k": 5,
    "mode": "hybrid",
    "elapsed_sec": 1586.9
  },
  "results": [
    {
      "id": "so-001",
      "topic": "pipelining",
      "question": "I'm building a Python app that needs to execute ~5000 Redis SET commands to update user session data. I've read about both pipelining and MULTI/EXEC transactions but I'm confused about the difference.",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/jedis/transpipe.md",
          "title": "Pipelines and transactions",
          "score": 1.7248
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/dotnet/transpipe.md",
          "title": "Pipelines and transactions",
          "score": 1.1589
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/nodejs/transpipe.md",
          "title": "Pipelines and transactions",
          "score": 0.1073
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/redis-py/transpipe.md",
          "title": "Pipelines and transactions",
          "score": 2.2776
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/using-commands/pipelining.md",
          "title": "Redis pipelining",
          "score": 2.1989
        }
      ]
    },
    {
      "id": "so-002",
      "topic": "pipelining",
      "question": "I'm using redis-py in a high-latency network environment (cross-region, ~50ms RTT). Sending 200 individual GET commands takes about 10 seconds. I know pipelining can help reduce round trip time by bat",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/using-commands/pipelining.md",
          "title": "Redis pipelining",
          "score": 2.6384
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/using-commands/pipelining.md",
          "title": "Redis pipelining",
          "score": 1.9128
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/using-commands/pipelining.md",
          "title": "Redis pipelining",
          "score": 0.593
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/redis-py/transpipe.md",
          "title": "Pipelines and transactions",
          "score": 2.1767
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/go/transpipe.md",
          "title": "Pipelines and transactions",
          "score": 1.8103
        }
      ]
    },
    {
      "id": "so-003",
      "topic": "sentinel",
      "question": "I have a Redis Sentinel setup with 3 sentinels and 1 master + 2 replicas on CentOS 7. When I stop the master with `redis-cli -p 6379 DEBUG SLEEP 60`, the sentinels detect +sdown but never reach +odown",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 2.2965
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 1.4916
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 1.1246
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 1.0529
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 0.8248
        }
      ]
    },
    {
      "id": "so-004",
      "topic": "sentinel",
      "question": "I'm setting up Redis Sentinel for high availability in production with 3 servers. Each server runs both a Redis instance and a Sentinel instance. Server A is master, B and C are replicas. I want autom",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 5.0319
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 3.6966
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 2.9928
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 4.5889
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 4.1737
        }
      ]
    },
    {
      "id": "so-005",
      "topic": "data-types",
      "question": "I'm building a real-time leaderboard for a mobile game with ~100K daily active users. I need to store player scores and quickly retrieve the top 100 players, as well as a specific player's rank. I ini",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/sorted-sets.md",
          "title": "Redis sorted sets",
          "score": 1.0761
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/sorted-sets.md",
          "title": "Redis sorted sets",
          "score": 0.8888
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/sorted-sets.md",
          "title": "Redis sorted sets",
          "score": -1.0542
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/databases/active-active/develop/data-types/sorted-sets.md",
          "title": "sorted-sets.md",
          "score": -0.8049
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.22/databases/active-active/develop/data-types/sorted-sets.md",
          "title": "sorted-sets.md",
          "score": -0.8049
        }
      ]
    },
    {
      "id": "so-006",
      "topic": "data-types",
      "question": "I'm trying to understand Redis internals for a systems design interview. I know Redis has Strings, Lists, Sets, Sorted Sets, and Hashes as user-facing data types, but what data structures does Redis a",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/_index.md",
          "title": "Redis data types",
          "score": 2.1483
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/lists.md",
          "title": "Redis lists",
          "score": 0.3702
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/optimization/memory-optimization.md",
          "title": "Memory optimization",
          "score": 0.1835
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/search-and-query/administration/overview.md",
          "title": "Technical overview",
          "score": 2.2211
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/compare-data-types.md",
          "title": "Compare data types",
          "score": 1.2925
        }
      ]
    },
    {
      "id": "so-007",
      "topic": "data-types",
      "question": "I need to store user profile data in Redis. Each user has fields like name, email, age, and preferences. I'm debating between using a Redis Hash (HSET user:123 name 'John' email 'john@example.com') vs",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.12.1/user_guide/hash_vs_json.md",
          "title": "Hash vs JSON Storage",
          "score": 2.3814
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.12.0/user_guide/hash_vs_json.md",
          "title": "Hash vs JSON Storage",
          "score": 2.3814
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.11.1/user_guide/hash_vs_json.md",
          "title": "Hash vs JSON Storage",
          "score": 2.3814
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.8.0/user_guide/hash_vs_json.md",
          "title": "Hash vs JSON Storage",
          "score": 3.0033
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.8.2/user_guide/hash_vs_json.md",
          "title": "Hash vs JSON Storage",
          "score": 3.0033
        }
      ]
    },
    {
      "id": "so-008",
      "topic": "persistence",
      "question": "I'm running Redis in production as a primary data store (not just cache) and need to configure persistence. I understand there are two options: RDB snapshots and AOF (Append Only File). RDB creates po",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.8/databases/configure/database-persistence.md",
          "title": "database-persistence.md",
          "score": 6.158
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.22/databases/configure/database-persistence.md",
          "title": "database-persistence.md",
          "score": 6.158
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
          "title": "Redis persistence",
          "score": 5.7006
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.4/databases/configure/database-persistence.md",
          "title": "database-persistence.md",
          "score": 6.158
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/databases/configure/database-persistence.md",
          "title": "database-persistence.md",
          "score": 6.1169
        }
      ]
    },
    {
      "id": "so-009",
      "topic": "persistence",
      "question": "I'm looking at my Redis AOF file and noticed it starts with the string 'REDIS' followed by binary data, which looks like an RDB preamble. Then the rest of the file has the normal AOF command format (*",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
          "title": "Redis persistence",
          "score": 3.0465
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
          "title": "Redis persistence",
          "score": 1.2247
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
          "title": "Redis persistence",
          "score": 0.246
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
          "title": "Redis persistence",
          "score": 1.9023
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
          "title": "Redis persistence",
          "score": 1.5331
        }
      ]
    },
    {
      "id": "so-010",
      "topic": "memory",
      "question": "I stored about 500MB of string data in Redis (verified by summing the sizes of all values), but `INFO memory` shows `used_memory_human: 4.8G` — almost 10x more than my actual data. I'm using Redis 6.2",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.4/references/metrics/resource-usage.md",
          "title": "resource-usage.md",
          "score": 0.7314
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/references/metrics/resource-usage.md",
          "title": "resource-usage.md",
          "score": 0.7314
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/optimization/memory-optimization.md",
          "title": "Memory optimization",
          "score": -0.0481
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.22/references/metrics/resource-usage.md",
          "title": "resource-usage.md",
          "score": 0.7314
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.8/references/metrics/resource-usage.md",
          "title": "resource-usage.md",
          "score": 0.7314
        }
      ]
    },
    {
      "id": "so-011",
      "topic": "memory",
      "question": "I'm running Redis as a session cache with `maxmemory 2gb` and `maxmemory-policy volatile-lru`. Today I noticed Redis is using 2.3GB according to `INFO memory`, which exceeds my maxmemory setting. I th",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/reference/eviction/index.md",
          "title": "Key eviction",
          "score": 5.2563
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/reference/eviction/index.md",
          "title": "Key eviction",
          "score": 4.8055
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/reference/eviction/index.md",
          "title": "Key eviction",
          "score": 3.251
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/databases/memory-performance/_index.md",
          "title": "_index.md",
          "score": 5.3213
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.4/databases/memory-performance/_index.md",
          "title": "_index.md",
          "score": 5.313
        }
      ]
    },
    {
      "id": "so-012",
      "topic": "security",
      "question": "I just upgraded to Redis 6.0 and want to use the new ACL feature to create separate users for different microservices. Currently everything connects with the default user and `requirepass`. I want to ",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/acl.md",
          "title": "ACL",
          "score": 3.0725
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rc/security/access-control/data-access-control/configure-acls.md",
          "title": "configure-acls.md",
          "score": 2.6943
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rc/security/access-control/data-access-control/configure-acls.md",
          "title": "configure-acls.md",
          "score": 1.2867
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/acl.md",
          "title": "ACL",
          "score": 1.8316
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/acl.md",
          "title": "ACL",
          "score": 1.7543
        }
      ]
    },
    {
      "id": "so-013",
      "topic": "security",
      "question": "I just installed Redis on an Ubuntu server and it's accessible without any authentication. I need to set a password before exposing it to the network. I know I can use `requirepass` in redis.conf, but",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/install/archive/install-redis/_index.md",
          "title": "Install Redis",
          "score": 4.1075
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/admin.md",
          "title": "Redis administration",
          "score": 3.6094
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/_index.md",
          "title": "Redis security",
          "score": 3.2296
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 2.3171
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/_index.md",
          "title": "Redis security",
          "score": 1.3033
        }
      ]
    },
    {
      "id": "so-014",
      "topic": "pubsub-streams",
      "question": "I need to implement a message queue in Redis for processing background jobs. I've been using Pub/Sub but realized that if a subscriber is disconnected when a message is published, it misses that messa",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/streams/_index.md",
          "title": "Redis Streams",
          "score": 4.987
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/streams/_index.md",
          "title": "Redis Streams",
          "score": 1.3172
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/pubsub/_index.md",
          "title": "Redis Pub/sub",
          "score": 0.8819
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/streams/_index.md",
          "title": "Redis Streams",
          "score": 2.7483
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/streams/_index.md",
          "title": "Redis Streams",
          "score": 2.7077
        }
      ]
    },
    {
      "id": "so-015",
      "topic": "cluster",
      "question": "I'm migrating from a single Redis instance to Redis Cluster for horizontal scaling. I understand the cluster uses 16384 hash slots distributed across nodes. When I run a command, Redis computes CRC16(",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/reference/cluster-spec.md",
          "title": "Redis cluster specification",
          "score": 4.6499
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/reference/cluster-spec.md",
          "title": "Redis cluster specification",
          "score": 4.2708
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/reference/cluster-spec.md",
          "title": "Redis cluster specification",
          "score": 1.8994
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/scaling.md",
          "title": "Scale with Redis Cluster",
          "score": 3.9463
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/scaling.md",
          "title": "Scale with Redis Cluster",
          "score": 2.901
        }
      ]
    },
    {
      "id": "so-016",
      "topic": "cluster",
      "question": "I need high availability for my Redis deployment and I'm confused about whether to use Redis Sentinel or Redis Cluster. My dataset is about 8GB and fits on a single machine. I don't need sharding, jus",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 5.8192
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 3.9393
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/reference/sentinel-clients.md",
          "title": "Sentinel client spec",
          "score": 3.5196
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 3.8871
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/reference/cluster-spec.md",
          "title": "Redis cluster specification",
          "score": 3.6098
        }
      ]
    },
    {
      "id": "so-017",
      "topic": "replication",
      "question": "I'm setting up Redis replication with 1 master and 2 replicas. During initial sync, I see in the logs that the master is doing a BGSAVE and sending the RDB file to the replica (full synchronization). ",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/replication.md",
          "title": "Redis replication",
          "score": 4.1062
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/replication.md",
          "title": "Redis replication",
          "score": 3.9984
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/replication.md",
          "title": "Redis replication",
          "score": 1.6453
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.22/databases/active-active/syncer.md",
          "title": "syncer.md",
          "score": 4.0456
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.4/databases/active-active/syncer.md",
          "title": "syncer.md",
          "score": 4.0456
        }
      ]
    },
    {
      "id": "so-018",
      "topic": "clients",
      "question": "I'm new to Redis and trying to connect from a Python application using redis-py. I installed it with `pip install redis` and wrote `r = redis.Redis(host='localhost', port=6379, db=0)` but I'm not sure",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/redis-py/connect.md",
          "title": "Connect to the server",
          "score": 3.7676
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/pools-and-muxing.md",
          "title": "Connection pools and multiplexing",
          "score": 2.4312
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/ioredis/connect.md",
          "title": "Connect to the server",
          "score": 2.3804
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/redis-py/_index.md",
          "title": "redis-py guide (Python)",
          "score": 4.056
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/lettuce/connect.md",
          "title": "Connect to the server",
          "score": 3.4159
        }
      ]
    },
    {
      "id": "so-019",
      "topic": "ai",
      "question": "I want to use Redis as a vector database for a RAG (Retrieval Augmented Generation) application. I have ~1M document embeddings (768-dimensional vectors from sentence-transformers) and need to do k-ne",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.11.1/_index.md",
          "title": "RedisVL",
          "score": 6.0509
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/search-and-query/vectors/_index.md",
          "title": "Vector search concepts",
          "score": 5.2417
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/redis-py/vecsearch.md",
          "title": "Index and query vectors",
          "score": 3.4528
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.11.0/_index.md",
          "title": "RedisVL",
          "score": 6.0509
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.9.1/_index.md",
          "title": "RedisVL",
          "score": 6.0509
        }
      ]
    },
    {
      "id": "so-020",
      "topic": "scripting",
      "question": "I need to implement a rate limiter in Redis that atomically checks and increments a counter. Using separate GET and INCR commands has a race condition in concurrent scenarios. I know I can use EVAL wi",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/programmability/eval-intro.md",
          "title": "Scripting with Lua",
          "score": 2.775
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/programmability/functions-intro.md",
          "title": "Redis functions",
          "score": 2.5611
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/programmability/eval-intro.md",
          "title": "Scripting with Lua",
          "score": 1.5772
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/programmability/eval-intro.md",
          "title": "Scripting with Lua",
          "score": 0.4486
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/programmability/_index.md",
          "title": "Redis programmability",
          "score": 0.4442
        }
      ]
    },
    {
      "id": "so-021",
      "topic": "security",
      "question": "I need to enable TLS encryption for Redis connections in production. Our security team requires all data in transit to be encrypted. I'm running Redis 6.2 and I see there's a `tls-port` config option.",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rc/security/database-security/tls-ssl.md",
          "title": "tls-ssl.md",
          "score": 5.0149
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/php/connect.md",
          "title": "Connect to the server",
          "score": 4.0716
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/encryption.md",
          "title": "TLS",
          "score": 3.9329
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/security/encryption/tls/tls-protocols.md",
          "title": "Configure TLS protocol",
          "score": 3.6163
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/security/encryption/_index.md",
          "title": "_index.md",
          "score": 3.5957
        }
      ]
    },
    {
      "id": "so-022",
      "topic": "cloud",
      "question": "I want to try Redis Cloud for a new project instead of self-hosting. How do I create a subscription and get a database endpoint? I see there's a free tier. After creating the database, how do I connec",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/stack-with-enterprise/stack-quickstart.md",
          "title": "Redis Open Source quick start",
          "score": 5.9492
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rc/rc-quickstart.md",
          "title": "rc-quickstart.md",
          "score": 2.9182
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/stack-with-enterprise/stack-quickstart.md",
          "title": "Redis Open Source quick start",
          "score": 2.294
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rc/api/_index.md",
          "title": "_index.md",
          "score": 4.6994
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.4/databases/connect/_index.md",
          "title": "_index.md",
          "score": 4.0033
        }
      ]
    },
    {
      "id": "so-023",
      "topic": "kubernetes",
      "question": "I'm deploying Redis Enterprise on Kubernetes using the Redis Enterprise Operator. I've installed the operator via Helm but I'm confused about the CRDs — there's RedisEnterpriseCluster and RedisEnterpr",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/kubernetes/7.4.6/deployment/_index.md",
          "title": "_index.md",
          "score": 5.051
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/kubernetes/7.4.6/faqs/_index.md",
          "title": "_index.md",
          "score": 3.1158
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/kubernetes/7.8.4/faqs/_index.md",
          "title": "_index.md",
          "score": 3.1158
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/kubernetes/deployment/_index.md",
          "title": "_index.md",
          "score": 5.8321
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/kubernetes/7.22/deployment/_index.md",
          "title": "_index.md",
          "score": 5.8321
        }
      ]
    },
    {
      "id": "so-024",
      "topic": "data-types",
      "question": "I need to store complex nested JSON documents in Redis and query them by nested fields. For example, I have user profiles like `{name: 'John', address: {city: 'NYC', zip: '10001'}, tags: ['premium', '",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/json/use_cases.md",
          "title": "Use cases",
          "score": 4.0657
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/user_guide/hash_vs_json.md",
          "title": "Hash vs JSON Storage",
          "score": 2.2434
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.9.0/user_guide/hash_vs_json.md",
          "title": "Hash vs JSON Storage",
          "score": 2.2434
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/patterns/indexes/index.md",
          "title": "Secondary indexing",
          "score": 3.4667
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.8.2/user_guide/hash_vs_json.md",
          "title": "Hash vs JSON Storage",
          "score": 2.2434
        }
      ]
    },
    {
      "id": "so-025",
      "topic": "benchmark",
      "question": "I want to benchmark my Redis server to establish a performance baseline before deploying to production. I know there's a built-in `redis-benchmark` tool. How do I use it to test specific commands like",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/optimization/benchmarks/index.md",
          "title": "Redis benchmark",
          "score": 3.8849
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/optimization/benchmarks/index.md",
          "title": "Redis benchmark",
          "score": 2.7448
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/json/performance/_index.md",
          "title": "Performance",
          "score": 1.6258
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/clusters/optimize/memtier-benchmark.md",
          "title": "memtier-benchmark.md",
          "score": 2.7208
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.4/clusters/optimize/memtier-benchmark.md",
          "title": "memtier-benchmark.md",
          "score": 2.5144
        }
      ]
    },
    {
      "id": "cn-001",
      "topic": "pipelining",
      "question": "我在用 Python 开发一个批量数据导入工具，需要往 Redis 里写入大约 5 万条数据。我看到 Redis 有 pipeline（管道）和 MULTI/EXEC（事务）两种批量执行方式。pipeline 是把多条命令打包发送减少网络往返，而事务是保证原子性执行。这两者能一起用吗？我的场景不需要原子性，只需要高吞吐，应该选哪个？pipeline 一次打包多少条命令比较合适？",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/hiredis/transpipe.md",
          "title": "Pipelines and transactions",
          "score": 2.4891
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/nodejs/transpipe.md",
          "title": "Pipelines and transactions",
          "score": 1.6851
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/using-commands/pipelining.md",
          "title": "Redis pipelining",
          "score": 1.5432
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/redis-py/transpipe.md",
          "title": "Pipelines and transactions",
          "score": 3.6773
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/clients/go/transpipe.md",
          "title": "Pipelines and transactions",
          "score": 3.3777
        }
      ]
    },
    {
      "id": "cn-002",
      "topic": "sentinel",
      "question": "我在 3 台 CentOS 服务器上部署了 Redis Sentinel 哨兵模式，1 主 2 从，每台机器上都跑了一个 sentinel 进程。配置了 `sentinel monitor mymaster 10.0.1.10 6379 2`，quorum 设为 2。但是当我手动 kill 掉 master 进程后，sentinel 日志只显示 +sdown，一直没有触发 +odown 和 fai",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 2.2436
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 1.8057
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 0.52
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 2.7674
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/sentinel.md",
          "title": "High availability with Redis Sentinel",
          "score": 2.5966
        }
      ]
    },
    {
      "id": "cn-003",
      "topic": "persistence",
      "question": "我们的 Redis 是作为主数据库使用的（不只是缓存），需要配置持久化防止数据丢失。RDB 是定时快照，AOF 是记录每条写命令。我担心 RDB 模式下如果 Redis 崩溃会丢失两次快照之间的数据（比如 5 分钟）。AOF 的 everysec 策略最多丢 1 秒数据，但听说有性能开销。生产环境应该用哪个？能不能 RDB 和 AOF 同时开启？Redis 7.0 的 AOF 文件格式是不是变了，",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
          "title": "Redis persistence",
          "score": 3.5152
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.8/databases/configure/database-persistence.md",
          "title": "database-persistence.md",
          "score": 3.3819
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
          "title": "Redis persistence",
          "score": 3.1335
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/persistence.md",
          "title": "Redis persistence",
          "score": 4.1894
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.4/databases/configure/database-persistence.md",
          "title": "database-persistence.md",
          "score": 3.3819
        }
      ]
    },
    {
      "id": "cn-004",
      "topic": "memory",
      "question": "我的 Redis 实例设置了 `maxmemory 4gb`，淘汰策略是 `volatile-lru`。但是 `INFO memory` 显示 `used_memory` 已经到了 4.6GB，超过了 maxmemory 限制。而且我发现一些没有设置 TTL 的 key 也被淘汰了，volatile-lru 不是应该只淘汰有过期时间的 key 吗？另外，`mem_fragmentation_rat",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/optimization/memory-optimization.md",
          "title": "Memory optimization",
          "score": 2.1905
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/databases/flash/_index.md",
          "title": "_index.md",
          "score": 1.9734
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/reference/eviction/index.md",
          "title": "Key eviction",
          "score": 1.9376
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/databases/memory-performance/_index.md",
          "title": "_index.md",
          "score": 2.8179
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.22/databases/memory-performance/_index.md",
          "title": "_index.md",
          "score": 2.738
        }
      ]
    },
    {
      "id": "cn-005",
      "topic": "cluster",
      "question": "我们要从单机 Redis 迁移到 Redis Cluster 集群模式。我知道集群用 16384 个哈希槽来分片数据，每个 key 通过 CRC16(key) % 16384 计算属于哪个槽。但我有几个疑问：1) 新加节点后需要手动迁移哈希槽吗？还是自动重新分配？2) 迁移过程中客户端会收到 MOVED 和 ASK 重定向，这两个有什么区别？3) 多 key 操作（如 MGET）在集群模式下是不是",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/scaling.md",
          "title": "Scale with Redis Cluster",
          "score": 4.7461
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/reference/cluster-spec.md",
          "title": "Redis cluster specification",
          "score": 4.4853
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/reference/cluster-spec.md",
          "title": "Redis cluster specification",
          "score": 2.2764
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/scaling.md",
          "title": "Scale with Redis Cluster",
          "score": 3.5691
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/scaling.md",
          "title": "Scale with Redis Cluster",
          "score": 3.0693
        }
      ]
    },
    {
      "id": "cn-006",
      "topic": "data-types",
      "question": "我在做一个手游实时排行榜，日活大概 10 万用户。需要存储玩家分数，快速查询 Top 100 和某个玩家的排名。一开始用 Redis List 存储，但更新分数需要先删除再插入，效率很低。后来看到 Sorted Set 可以用 ZADD 更新分数、ZREVRANK 查排名、ZREVRANGE 取 Top N，时间复杂度都是 O(log N)。Sorted Set 和 List 各自适合什么场景？如",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/sorted-sets.md",
          "title": "Redis sorted sets",
          "score": 0.8814
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/sorted-sets.md",
          "title": "Redis sorted sets",
          "score": 0.5551
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/sorted-sets.md",
          "title": "Redis sorted sets",
          "score": -2.0114
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/compare-data-types.md",
          "title": "Compare data types",
          "score": 0.7425
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/databases/active-active/develop/data-types/sorted-sets.md",
          "title": "sorted-sets.md",
          "score": 0.263
        }
      ]
    },
    {
      "id": "cn-007",
      "topic": "pubsub-streams",
      "question": "我需要在 Redis 里实现一个消息队列来处理异步任务。之前用 Pub/Sub 做的，但发现如果消费者断线期间发布的消息会丢失，没有重放机制。而且 Pub/Sub 没有消息确认，消费者处理失败了消息就没了。听说 Redis 5.0 引入的 Streams 支持消费者组、消息持久化和 ACK 确认机制（XADD/XREADGROUP/XACK）。Pub/Sub 和 Streams 的主要区别是什么？",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/streams/_index.md",
          "title": "Redis Streams",
          "score": 3.3485
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/tools/insight/release-notes/v.2.4.0.md",
          "title": "v.2.4.0.md",
          "score": 1.4664
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/pubsub/_index.md",
          "title": "Redis Pub/sub",
          "score": 0.4899
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/streams/_index.md",
          "title": "Redis Streams",
          "score": 2.5596
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/data-types/streams/_index.md",
          "title": "Redis Streams",
          "score": 2.5052
        }
      ]
    },
    {
      "id": "cn-008",
      "topic": "security",
      "question": "我们升级到 Redis 6.0 后想用 ACL 功能给不同的微服务分配不同的访问权限。之前所有服务都用同一个 requirepass 密码连接。现在想创建一个只读用户 'readonly' 只能执行 GET/HGETALL 等读命令，访问 'cache:*' 前缀的 key；另一个用户 'admin' 有完全权限。ACL SETUSER 的语法是什么？key 的模式匹配怎么写？能不能限制用户只能访",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rc/security/access-control/data-access-control/configure-acls.md",
          "title": "configure-acls.md",
          "score": 3.0736
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/acl.md",
          "title": "ACL",
          "score": 2.7166
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/acl.md",
          "title": "ACL",
          "score": 2.6743
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/security/acl.md",
          "title": "ACL",
          "score": 3.4733
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rc/security/access-control/data-access-control/configure-acls.md",
          "title": "configure-acls.md",
          "score": 3.1716
        }
      ]
    },
    {
      "id": "cn-009",
      "topic": "ai",
      "question": "我想用 Redis 做向量相似度搜索，存储大约 100 万条文档的 embedding 向量（768 维，用 sentence-transformers 生成）。需要支持 KNN 查询找最相似的 Top-K 文档。我看到 Redis Stack 有向量搜索功能，支持 FLAT 和 HNSW 两种索引类型。FLAT 是暴力搜索，HNSW 是近似最近邻。100 万条数据应该选哪种？有没有 Python",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/stack-with-enterprise/release-notes/redisearch/redisearch-2.4-release-notes.md",
          "title": "redisearch-2.4-release-notes.md",
          "score": 3.4078
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.12.1/api/schema.md",
          "title": "Schema",
          "score": 2.8052
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/api/schema.md",
          "title": "Schema",
          "score": 2.8052
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.8.1/_index.md",
          "title": "RedisVL",
          "score": 4.6358
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/develop/ai/redisvl/0.6.0/_index.md",
          "title": "RedisVL",
          "score": 4.6358
        }
      ]
    },
    {
      "id": "cn-010",
      "topic": "replication",
      "question": "我在搭建 Redis 主从复制，1 主 2 从。初始同步时看到 master 日志在做 BGSAVE 然后把 RDB 文件发给 replica（全量同步）。同步完成后切换到增量的复制流。我的问题是：1) 什么情况下会触发全量同步？什么情况下是增量同步？2) 如果 replica 短暂断开后重连，是不是一定要重新全量同步？3) repl-backlog-size 复制积压缓冲区应该设多大才能避免不必",
      "status": "PASS",
      "hits": [
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.8/references/rest-api/objects/bdb/replica_sync.md",
          "title": "replica_sync.md",
          "score": -1.1206
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/7.22/references/rest-api/objects/bdb/replica_sync.md",
          "title": "replica_sync.md",
          "score": -1.1206
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/rs/references/rest-api/objects/bdb/replica_sync.md",
          "title": "replica_sync.md",
          "score": -1.1206
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/replication.md",
          "title": "Redis replication",
          "score": 3.2973
        },
        {
          "path": "kb/kb-redis-docs/docs/redis-docs/operate/oss_and_stack/management/replication.md",
          "title": "Redis replication",
          "score": 1.4342
        }
      ]
    }
  ]
}