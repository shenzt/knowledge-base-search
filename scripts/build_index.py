#!/usr/bin/env python3
"""æ„å»ºçŸ¥è¯†åº“åˆ†å±‚ç´¢å¼•"""

import json
import yaml
from pathlib import Path
from datetime import datetime
from collections import defaultdict
import hashlib

def extract_frontmatter(md_file):
    """æå– Markdown æ–‡ä»¶çš„ front-matter"""
    try:
        with open(md_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æ£€æŸ¥æ˜¯å¦æœ‰ front-matter
        if not content.startswith('---'):
            return None

        # æå– front-matter
        parts = content.split('---', 2)
        if len(parts) < 3:
            return None

        frontmatter_str = parts[1].strip()

        # è§£æ YAML
        try:
            frontmatter = yaml.safe_load(frontmatter_str)
            return frontmatter
        except:
            return None
    except Exception as e:
        print(f"  è­¦å‘Š: æ— æ³•è¯»å– {md_file.name} - {e}")
        return None

def generate_doc_id(file_path):
    """ä¸ºæ²¡æœ‰ ID çš„æ–‡æ¡£ç”Ÿæˆ ID"""
    # ä½¿ç”¨æ–‡ä»¶è·¯å¾„çš„å“ˆå¸Œ
    path_str = str(file_path)
    return hashlib.md5(path_str.encode()).hexdigest()[:8]

def build_index(docs_dir):
    """æ„å»ºåˆ†å±‚ç´¢å¼•"""
    docs_dir = Path(docs_dir)

    if not docs_dir.exists():
        print(f"é”™è¯¯: ç›®å½•ä¸å­˜åœ¨ - {docs_dir}")
        return None

    print(f"æ‰«æç›®å½•: {docs_dir}")

    # æŸ¥æ‰¾æ‰€æœ‰ Markdown æ–‡ä»¶
    md_files = list(docs_dir.rglob("*.md"))
    print(f"æ‰¾åˆ° {len(md_files)} ä¸ª Markdown æ–‡ä»¶\n")

    # æ„å»ºç´¢å¼•ç»“æ„
    index = {
        "generated": datetime.now().isoformat(),
        "total_docs": 0,
        "structure": {},
        "tags_index": defaultdict(list),
        "categories": defaultdict(int),
        "confidence_levels": defaultdict(int)
    }

    # å¤„ç†æ¯ä¸ªæ–‡æ¡£
    for i, md_file in enumerate(md_files, 1):
        if i % 10 == 0:
            print(f"å¤„ç†ä¸­... {i}/{len(md_files)}")

        # æå– front-matter
        frontmatter = extract_frontmatter(md_file)

        # è®¡ç®—ç›¸å¯¹è·¯å¾„
        rel_path = md_file.relative_to(docs_dir)
        dir_path = str(rel_path.parent) if rel_path.parent != Path('.') else "root"

        # ç¡®ä¿ç›®å½•å­˜åœ¨äºç»“æ„ä¸­
        if dir_path not in index["structure"]:
            index["structure"][dir_path] = {
                "path": str(docs_dir / dir_path),
                "count": 0,
                "documents": []
            }

        # æ„å»ºæ–‡æ¡£æ¡ç›®
        doc_entry = {
            "path": str(rel_path),
            "full_path": str(md_file)
        }

        if frontmatter:
            doc_entry["id"] = frontmatter.get("id", generate_doc_id(rel_path))
            doc_entry["title"] = frontmatter.get("title", md_file.stem)
            doc_entry["tags"] = frontmatter.get("tags", [])
            doc_entry["confidence"] = frontmatter.get("confidence", "unknown")
            doc_entry["category"] = frontmatter.get("category", "uncategorized")
            doc_entry["last_reviewed"] = frontmatter.get("last_reviewed", "")

            # æ›´æ–°æ ‡ç­¾ç´¢å¼•
            for tag in doc_entry["tags"]:
                index["tags_index"][tag].append(doc_entry["id"])

            # æ›´æ–°åˆ†ç±»ç»Ÿè®¡
            index["categories"][doc_entry["category"]] += 1

            # æ›´æ–°ç½®ä¿¡åº¦ç»Ÿè®¡
            index["confidence_levels"][doc_entry["confidence"]] += 1
        else:
            # æ²¡æœ‰ front-matter
            doc_entry["id"] = generate_doc_id(rel_path)
            doc_entry["title"] = md_file.stem
            doc_entry["tags"] = []
            doc_entry["confidence"] = "unknown"
            doc_entry["category"] = "uncategorized"
            doc_entry["last_reviewed"] = ""

            index["confidence_levels"]["unknown"] += 1
            index["categories"]["uncategorized"] += 1

        # æ·»åŠ åˆ°ç»“æ„
        index["structure"][dir_path]["documents"].append(doc_entry)
        index["structure"][dir_path]["count"] += 1
        index["total_docs"] += 1

    # è½¬æ¢ defaultdict ä¸ºæ™®é€š dict
    index["tags_index"] = dict(index["tags_index"])
    index["categories"] = dict(index["categories"])
    index["confidence_levels"] = dict(index["confidence_levels"])

    print(f"\nâœ… ç´¢å¼•æ„å»ºå®Œæˆ!")
    print(f"   æ€»æ–‡æ¡£æ•°: {index['total_docs']}")
    print(f"   ç›®å½•æ•°: {len(index['structure'])}")
    print(f"   æ ‡ç­¾æ•°: {len(index['tags_index'])}")

    return index

def save_json_index(index, output_path):
    """ä¿å­˜ JSON æ ¼å¼ç´¢å¼•"""
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(index, f, ensure_ascii=False, indent=2)
    print(f"\nâœ… JSON ç´¢å¼•å·²ä¿å­˜: {output_path}")

def save_markdown_index(index, output_path):
    """ä¿å­˜ Markdown æ ¼å¼ç´¢å¼•"""
    lines = []

    lines.append("# çŸ¥è¯†åº“ç´¢å¼•\n")
    lines.append(f"> ç”Ÿæˆæ—¶é—´: {index['generated']}\n")
    lines.append(f"> æ€»æ–‡æ¡£æ•°: {index['total_docs']}\n")
    lines.append("\n## ç›®å½•ç»“æ„\n")

    # æŒ‰ç›®å½•ç»„ç»‡
    for dir_path, dir_info in sorted(index["structure"].items()):
        lines.append(f"\n### {dir_path}/ ({dir_info['count']} ç¯‡)\n")

        for doc in dir_info["documents"]:
            confidence_icon = {
                "high": "â­",
                "medium": "ğŸ“",
                "low": "âš ï¸",
                "deprecated": "âŒ",
                "unknown": "â“"
            }.get(doc["confidence"], "")

            tags_str = " ".join([f"`#{tag}`" for tag in doc["tags"]]) if doc["tags"] else ""
            lines.append(f"- [{doc['title']}]({doc['path']}) {confidence_icon} {tags_str}\n")

    # æ ‡ç­¾ç´¢å¼•
    if index["tags_index"]:
        lines.append("\n## æŒ‰æ ‡ç­¾åˆ†ç±»\n")
        for tag, doc_ids in sorted(index["tags_index"].items()):
            lines.append(f"\n### #{tag} ({len(doc_ids)} ç¯‡)\n")

    # ç»Ÿè®¡ä¿¡æ¯
    lines.append("\n## ç»Ÿè®¡ä¿¡æ¯\n")

    lines.append("\n### æŒ‰åˆ†ç±»\n")
    for category, count in sorted(index["categories"].items(), key=lambda x: x[1], reverse=True):
        lines.append(f"- {category}: {count} ç¯‡\n")

    lines.append("\n### æŒ‰ç½®ä¿¡åº¦\n")
    for confidence, count in sorted(index["confidence_levels"].items(), key=lambda x: x[1], reverse=True):
        icon = {"high": "â­", "medium": "ğŸ“", "low": "âš ï¸", "deprecated": "âŒ", "unknown": "â“"}.get(confidence, "")
        lines.append(f"- {icon} {confidence}: {count} ç¯‡\n")

    with open(output_path, 'w', encoding='utf-8') as f:
        f.writelines(lines)

    print(f"âœ… Markdown ç´¢å¼•å·²ä¿å­˜: {output_path}")

def main():
    import sys

    if len(sys.argv) < 2:
        print("ç”¨æ³•: python build_index.py <æ–‡æ¡£ç›®å½•>")
        sys.exit(1)

    docs_dir = sys.argv[1]

    # æ„å»ºç´¢å¼•
    index = build_index(docs_dir)

    if not index:
        sys.exit(1)

    # ä¿å­˜ç´¢å¼•
    output_dir = Path(docs_dir)
    save_json_index(index, output_dir / "index.json")
    save_markdown_index(index, output_dir / "INDEX.md")

    print(f"\n{'='*80}")
    print("ç´¢å¼•æ„å»ºå®Œæˆ!")
    print(f"{'='*80}")

if __name__ == '__main__':
    main()
