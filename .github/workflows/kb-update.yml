name: KB Update

# Sync source docs to KB repo + LLM preprocess + indexing via OpenRouter API.
# Snapshot is exported and committed to KB repo for local restore.
#
# Usage:
#   1. Trigger this workflow to sync latest docs + preprocess + index
#   2. Pull locally, restore snapshot: .venv/bin/python scripts/index.py --snapshot-import kb/kb-redis-docs/snapshots/latest.snapshot

on:
  workflow_dispatch:
    inputs:
      kb_name:
        description: "KB repo name"
        required: true
        default: "kb-redis-docs"
        type: choice
        options:
          - kb-redis-docs
      source_repo:
        description: "Source docs Git repo URL"
        required: true
        default: "https://github.com/redis/docs.git"
      source_subdir:
        description: "Subdirectory within source repo (e.g. content)"
        required: false
        default: "content"
      doc_filter:
        description: "Only sync these subdirs (comma-separated, empty = all)"
        required: false
        default: "develop,operate"
      skip_preprocess:
        description: "Skip LLM preprocessing"
        required: false
        default: false
        type: boolean
      skip_indexing:
        description: "Skip indexing (embedding + Qdrant)"
        required: false
        default: false
        type: boolean
      regenerate_index:
        description: "Regenerate INDEX.md (Agent explores repo structure)"
        required: false
        default: false
        type: boolean

jobs:
  sync-docs:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    services:
      qdrant:
        image: qdrant/qdrant:latest
        ports:
          - 6333:6333
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
          lfs: true
          token: ${{ secrets.KB_PUSH_TOKEN }}

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: scripts/requirements.txt

      - name: Install dependencies
        run: pip install -r scripts/requirements.txt

      - name: Clone source repo
        run: |
          git clone --depth 1 ${{ inputs.source_repo }} /tmp/source-docs

          SOURCE_ROOT="/tmp/source-docs"
          if [ -n "${{ inputs.source_subdir }}" ]; then
            SOURCE_ROOT="/tmp/source-docs/${{ inputs.source_subdir }}"
          fi
          echo "SOURCE_ROOT=$SOURCE_ROOT" >> $GITHUB_ENV

          DOC_COUNT=$(find "$SOURCE_ROOT" -name "*.md" | wc -l)
          echo "Source has $DOC_COUNT markdown files"

      - name: Sync docs to KB repo
        run: |
          KB_REPO="kb/${{ inputs.kb_name }}"
          KB_NAME="${{ inputs.kb_name }}"
          DOC_SUBDIR="${KB_NAME#kb-}"
          FILTER="${{ inputs.doc_filter }}"

          if [ -n "$FILTER" ]; then
            # Sync only specified subdirs
            mkdir -p "$KB_REPO/docs/$DOC_SUBDIR"
            IFS=',' read -ra DIRS <<< "$FILTER"
            for dir in "${DIRS[@]}"; do
              dir=$(echo "$dir" | xargs)  # trim whitespace
              if [ -d "$SOURCE_ROOT/$dir" ]; then
                mkdir -p "$KB_REPO/docs/$DOC_SUBDIR/$dir"
                rsync -a --delete "$SOURCE_ROOT/$dir/" "$KB_REPO/docs/$DOC_SUBDIR/$dir/"
                echo "Synced: $dir"
              else
                echo "WARNING: $SOURCE_ROOT/$dir not found, skipping"
              fi
            done
          else
            # Sync everything
            mkdir -p "$KB_REPO/docs/$DOC_SUBDIR"
            rsync -a --delete "$SOURCE_ROOT/" "$KB_REPO/docs/$DOC_SUBDIR/"
          fi

          DOC_COUNT=$(find "$KB_REPO/docs/$DOC_SUBDIR" -name "*.md" | wc -l)
          echo "KB repo now has $DOC_COUNT markdown files"

          echo "DOC_SUBDIR=$DOC_SUBDIR" >> $GITHUB_ENV
          echo "KB_REPO=$KB_REPO" >> $GITHUB_ENV
          echo "DOC_COUNT=$DOC_COUNT" >> $GITHUB_ENV

      - name: Clean stale preprocess files
        run: |
          # Remove .preprocess/ sidecar files whose source doc no longer exists
          find "$KB_REPO/docs/$DOC_SUBDIR" -type d -name ".preprocess" | while read pdir; do
            parent=$(dirname "$pdir")
            removed=0
            for json in "$pdir"/*.json; do
              [ -f "$json" ] || continue
              base=$(basename "$json" .json)
              if [ ! -f "$parent/$base" ]; then
                rm -f "$json"
                removed=$((removed + 1))
              fi
            done
            [ "$removed" -gt 0 ] && echo "Cleaned $removed stale files in $pdir"
            rmdir "$pdir" 2>/dev/null || true
          done

      - name: Preprocess docs (LLM analysis)
        if: ${{ !inputs.skip_preprocess }}
        run: |
          python scripts/doc_preprocess.py --dir "$KB_REPO/docs/$DOC_SUBDIR"
        env:
          DOC_PROCESS_PROVIDER: openai
          DOC_PROCESS_MODEL: deepseek-chat
          DOC_PROCESS_BASE_URL: https://api.deepseek.com
          DOC_PROCESS_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
          PREPROCESS_WORKERS: "16"

      - name: Generate INDEX.md (DeepSeek)
        if: ${{ inputs.regenerate_index == true }}
        run: |
          python scripts/generate_index.py "$KB_REPO"
        env:
          INDEX_GEN_PROVIDER: openai
          INDEX_GEN_MODEL: deepseek-chat
          INDEX_GEN_BASE_URL: https://api.deepseek.com
          INDEX_GEN_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}

      - name: Build index (OpenRouter BGE-M3 API)
        if: ${{ !inputs.skip_indexing }}
        run: |
          echo "Waiting for Qdrant to be ready..."
          for i in $(seq 1 30); do
            if curl -sf http://localhost:6333/healthz > /dev/null 2>&1; then
              echo "Qdrant is ready"
              break
            fi
            sleep 2
          done

          python scripts/index.py --full "$KB_REPO/docs/$DOC_SUBDIR"
        env:
          QDRANT_URL: http://localhost:6333
          EMBEDDING_PROVIDER: openai
          EMBEDDING_BASE_URL: https://openrouter.ai/api/v1
          EMBEDDING_API_KEY: ${{ secrets.EMBEDDING_API_KEY }}
          EMBEDDING_MODEL: baai/bge-m3
          EMBEDDING_DIM: "1024"
          EMBEDDING_CONCURRENCY: "6"

      - name: Export snapshot
        if: ${{ !inputs.skip_indexing }}
        run: |
          SNAPSHOT_DIR="$KB_REPO/snapshots"
          mkdir -p "$SNAPSHOT_DIR"
          python scripts/index.py --snapshot-export "$SNAPSHOT_DIR/latest.snapshot"
          ls -lh "$SNAPSHOT_DIR/latest.snapshot"
          echo "SNAPSHOT_EXPORTED=true" >> $GITHUB_ENV

      - name: Commit and push KB repo
        run: |
          cd "$KB_REPO"
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          # Set push URL with token for auth
          git remote set-url origin "https://x-access-token:${{ secrets.KB_PUSH_TOKEN }}@github.com/shenzt/${{ inputs.kb_name }}.git"
          # Add all files first (while in detached HEAD), then create branch
          git add -A
          if git diff --cached --quiet; then
            echo "No doc changes"
          else
            # Create main branch from current detached HEAD with staged changes
            git checkout -B main
            git commit -m "docs: sync $DOC_SUBDIR from upstream ($(date +%Y-%m-%d))

          $DOC_COUNT markdown files
          Source: ${{ inputs.source_repo }}
          Filter: ${{ inputs.doc_filter || 'all' }}"
            git push origin main --force
            echo "Pushed docs to KB repo"
          fi

      - name: Update submodule reference
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add "kb/${{ inputs.kb_name }}"
          if git diff --cached --quiet; then
            echo "Submodule ref unchanged"
          else
            git commit -m "chore: update ${{ inputs.kb_name }} submodule ref"
            git push
            echo "Updated submodule ref"
          fi

      - name: Summary
        run: |
          echo "## KB Update Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- KB: ${{ inputs.kb_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- Source: ${{ inputs.source_repo }}" >> $GITHUB_STEP_SUMMARY
          echo "- Filter: ${{ inputs.doc_filter || 'all' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Docs synced: $DOC_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "- Preprocess: ${{ inputs.skip_preprocess && 'skipped' || 'done' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Indexing: ${{ inputs.skip_indexing && 'skipped' || 'done' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Snapshot: ${SNAPSHOT_EXPORTED:-false}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ "${SNAPSHOT_EXPORTED}" = "true" ]; then
            echo "**Next step**: Pull and restore snapshot locally:" >> $GITHUB_STEP_SUMMARY
            echo '```bash' >> $GITHUB_STEP_SUMMARY
            echo "git pull && git submodule update --remote kb/${{ inputs.kb_name }}" >> $GITHUB_STEP_SUMMARY
            echo ".venv/bin/python scripts/index.py --snapshot-import kb/${{ inputs.kb_name }}/snapshots/latest.snapshot" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "**Next step**: Run locally to rebuild index + snapshot:" >> $GITHUB_STEP_SUMMARY
            echo '```bash' >> $GITHUB_STEP_SUMMARY
            echo "git pull && git submodule update --remote kb/${{ inputs.kb_name }}" >> $GITHUB_STEP_SUMMARY
            echo "scripts/preprocess_pipeline.sh --kb-repo kb/${{ inputs.kb_name }} --source kb/${{ inputs.kb_name }}/docs/${DOC_SUBDIR} --skip-preprocess" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
